{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=5\n",
    "b= 10\n",
    "from datetime import timedelta\n",
    "import time\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from functools import partial\n",
    "import itertools\n",
    "\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def __removeChatteringAlarmsHelper(self,alarms,chattering_timedelta_threshold=60.0, chattering_count_threshold=2):\n",
    "#         \"\"\"Find the chatterings in an alarms list from the same source.  \n",
    "#         \"\"\"\n",
    "\n",
    "#         alarms_without_chattering = []\n",
    "#         alarms = [alarm for alarm in sorted(alarms, key=lambda arg: arg[\"StartTime\"], reverse=False)]\n",
    "#         i = 0\n",
    "#         j = 0\n",
    "\n",
    "#         while i < (len(alarms)):\n",
    "#             alarms_without_chattering.append(alarms[i])\n",
    "#             prev_start = alarms[i][\"StartTime\"]\n",
    "#             prev_end = alarms[i][\"EndTime\"]\n",
    "#             count_alarms = 0\n",
    "#             j = i + 1\n",
    "#             while j < len(alarms):\n",
    "#                 next_start = alarms[j][\"StartTime\"]\n",
    "#                 next_end = alarms[j][\"EndTime\"]\n",
    "\n",
    "#                 # this assert is very important: the prev alarm has to turn off before the start of\n",
    "#                 # the next one\n",
    "#                 assert(prev_start <= next_start)\n",
    "#                 assert(prev_end <= next_start)\n",
    "#                 assert(prev_end <= next_end)\n",
    "\n",
    "#                 delta = timedelta.total_seconds(next_start - prev_start)\n",
    "#                 assert (delta >= 0)\n",
    "                \n",
    "#                 if delta > chattering_timedelta_threshold:\n",
    "#                     break\n",
    "#                 count_alarms += 1\n",
    "                \n",
    "#                 j += 1\n",
    "            \n",
    "#             if count_alarms >= chattering_count_threshold:\n",
    "#                 i = j\n",
    "#             else:\n",
    "#                 i += 1\n",
    "\n",
    "#         return alarms_without_chattering\n",
    "\n",
    "#     def removeChatteringAlarms(self,df,chattering_timedelta_threshold=120):\n",
    "#         alarms_without_chatterings = []\n",
    "#         for sname in df[\"SourceName\"].unique():\n",
    "#             df_source = df.loc[df['SourceName'].isin([sname])]\n",
    "\n",
    "#             for condition in df_source[\"Condition\"].unique():\n",
    "#                 df_condition = df_source.loc[df_source['Condition'].isin([condition])]\n",
    "#                 alarms = self.__removeChatteringAlarmsHelper(df_condition.to_dict(orient=\"records\"),chattering_timedelta_threshold=chattering_timedelta_threshold)\n",
    "#                 alarms_without_chatterings = alarms_without_chatterings + alarms\n",
    "\n",
    "#         return pd.DataFrame(alarms_without_chatterings)\n",
    "\n",
    "\n",
    "\n",
    "class AlarmsProcessing:\n",
    "    def __init__(self,config) -> None:\n",
    "        self.config = config\n",
    "        self.alias2name = None\n",
    "        self.name2alias = None\n",
    "        self.df = pd.read_csv(self.config['file-path'], low_memory=False, usecols=self.config['usecols'],parse_dates=self.config['date-cols'])\n",
    "        if self.config['alias']:\n",
    "            self.convertSourceNamesToAlias()\n",
    "    \n",
    "    def convertSourceNamesToAlias(self):\n",
    "        alias2name = {f\"A{k}\": v for k, v in enumerate(self.df[\"SourceName\"].unique())}\n",
    "        name2alias = {v: k for k, v in alias2name.items()}\n",
    "        self.df[\"SourceName\"] = self.df[\"SourceName\"].apply(lambda sname: name2alias[sname])\n",
    "        self.alias2name = alias2name\n",
    "        self.name2alias = name2alias\n",
    "        # return name2alias, alias2name\n",
    "\n",
    "    def __removeChatteringAlarmsHelper(self,alarms,chattering_timedelta_threshold, chattering_count_threshold):\n",
    "        \"\"\"Find the chatterings in an alarms list from the same source.  \n",
    "        \"\"\"\n",
    "\n",
    "        alarms_without_chattering = []\n",
    "        alarms = [alarm for alarm in sorted(alarms, key=lambda arg: arg[\"StartTime\"], reverse=False)]\n",
    "        i = 0\n",
    "        j = 0\n",
    "\n",
    "        while i < (len(alarms)):\n",
    "            alarms_without_chattering.append(alarms[i])\n",
    "            prev_start = alarms[i][\"StartTime\"]\n",
    "            prev_end = alarms[i][\"EndTime\"]\n",
    "            count_alarms = 0\n",
    "            j = i + 1\n",
    "            while j < len(alarms):\n",
    "                next_start = alarms[j][\"StartTime\"]\n",
    "                next_end = alarms[j][\"EndTime\"]\n",
    "\n",
    "                # this assert is very important: the prev alarm has to turn off before the start of\n",
    "                # the next one\n",
    "                assert(prev_start <= next_start)\n",
    "                assert(prev_end <= next_start)\n",
    "                assert(prev_end <= next_end)\n",
    "\n",
    "                delta = timedelta.total_seconds(next_start - prev_start)\n",
    "                assert (delta >= 0)\n",
    "                \n",
    "                if delta > chattering_timedelta_threshold:\n",
    "                    break\n",
    "                count_alarms += 1\n",
    "                \n",
    "                j += 1\n",
    "            \n",
    "            if count_alarms >= chattering_count_threshold:\n",
    "                i = j\n",
    "            else:\n",
    "                i += 1\n",
    "\n",
    "        return alarms_without_chattering\n",
    "\n",
    "    def removeChatteringAlarms(self,df,chattering_timedelta_threshold=60,chattering_count_threshold=2):\n",
    "        alarms_without_chatterings = []\n",
    "        for sname in df[\"SourceName\"].unique():\n",
    "            df_source = df.loc[df['SourceName'].isin([sname])]\n",
    "\n",
    "            for condition in df_source[\"Condition\"].unique():\n",
    "                df_condition = df_source.loc[df_source['Condition'].isin([condition])]\n",
    "                alarms = self.__removeChatteringAlarmsHelper(df_condition.to_dict(orient=\"records\"),chattering_timedelta_threshold=chattering_timedelta_threshold,chattering_count_threshold=chattering_count_threshold)\n",
    "                alarms_without_chatterings = alarms_without_chatterings + alarms\n",
    "\n",
    "        return pd.DataFrame(alarms_without_chatterings)\n",
    "\n",
    "    def removeMomentaryAlarms(self,df,monmentarly_filter=None):\n",
    "        df = df[(df[\"TimeDelta\"] > monmentarly_filter)].reset_index(drop=True)\n",
    "        return df\n",
    "\n",
    "    def removeStalingAlarms(self,df,staling_filter=None):\n",
    "        df =  df[(df[\"TimeDelta\"] < staling_filter)].reset_index(drop=True)\n",
    "        return df\n",
    "\n",
    "    def removeConditionsAlarms(self,df,conditions_filter):\n",
    "        df = df[~df[\"Condition\"].isin(conditions_filter)].reset_index(drop=True)\n",
    "        return df\n",
    "\n",
    "    def removeSources(self,df, sources_filter):\n",
    "        df = df[(~df[\"SourceName\"].isin(sources_filter))].reset_index(drop=True)\n",
    "        return df\n",
    "    \n",
    "    def removeSourcesBasedOnMinCount(self,df,min_alarms_per_source_filter):\n",
    "        source2count = dict(df[\"SourceName\"].value_counts())\n",
    "        select_sources = [k for k, v in source2count.items() if v >= min_alarms_per_source_filter]\n",
    "        df = df[df[\"SourceName\"].isin(select_sources)]\n",
    "        return df\n",
    "\n",
    "    def getDFWithCommonSourcesInAllMonths(self,df):\n",
    "        each_month_source_names = [[sname for sname in df[df[\"Year-Month\"]==month][\"SourceName\"].unique()] for month in df[\"Year-Month\"].unique()]\n",
    "        common_sourcenames_in_all_months = set.intersection(*[set(l) for l in each_month_source_names])\n",
    "        df = df[df[\"SourceName\"].isin(common_sourcenames_in_all_months)]\n",
    "        return df\n",
    "      \n",
    "    def updatSourceNamewithCondition(self,df):\n",
    "        def _concatenateSourceNameAndCondition(sname, condition):\n",
    "            return sname+\"-\"+condition\n",
    "        df[\"SourceName\"] = df[[\"SourceName\", \"Condition\"]].apply(\n",
    "            lambda arg: _concatenateSourceNameAndCondition(*arg), axis=1)\n",
    "        return df\n",
    "    \n",
    "    def getCondition2Sources(self,df,condition):\n",
    "        return df[df[\"Condition\"]==condition][\"SourceName\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrepareDataset:\n",
    "    def __init__(self,config) -> None:\n",
    "        self.config = config\n",
    "\n",
    "    def getSequenceOfWholeData(self,df,seq_duration_gap,filter_short_seq):\n",
    "        print(f\">> Duration to next seq: {seq_duration_gap}, ignore seq len: {filter_short_seq}\")\n",
    "\n",
    "        list_of_sequences = []    \n",
    "        alarms= df.sort_values(by='StartTime', ascending=True).reset_index(drop=True).to_dict(orient=\"records\")\n",
    "        alarms = [alarm for alarm in sorted(alarms, key=lambda arg: arg[\"StartTime\"], reverse=False)] # sorting\n",
    "\n",
    "        print('check',len(alarms))\n",
    "        assert alarms[0]['StartTime'] < alarms[-1]['StartTime']\n",
    "        i =0\n",
    "        j= 0\n",
    "\n",
    "        max_seq_len = -1\n",
    "        while i <len(alarms):\n",
    "            prev_start = alarms[i][\"StartTime\"]\n",
    "            seq = []\n",
    "            seq.append(alarms[i])\n",
    "            j = i+1\n",
    "            while j < len(alarms):    \n",
    "                next_start = alarms[j][\"StartTime\"]\n",
    "                delta = timedelta.total_seconds(next_start - prev_start)\n",
    "                # print(delta)\n",
    "                assert delta >= 0\n",
    "                if delta >= seq_duration_gap:\n",
    "                    break\n",
    "\n",
    "                seq.append(alarms[j])\n",
    "                j += 1\n",
    "            i = j\n",
    "\n",
    "            if len(seq) > max_seq_len:\n",
    "                max_seq_len = len(seq)\n",
    "            \n",
    "            if len(seq)>=filter_short_seq:\n",
    "                seq = [alarm for alarm in sorted(seq, key=lambda arg: arg[\"StartTime\"], reverse=False)]\n",
    "                seq = [alarm[\"SourceName\"] for alarm in seq]\n",
    "                list_of_sequences.append(seq)\n",
    "        \n",
    "        \n",
    "        return list_of_sequences, max_seq_len\n",
    "\n",
    "\n",
    "    def splitDFtoTrainValidDfsPerMonth(self,df,p=0.2):    \n",
    "        tarain_dfs = []\n",
    "        valid_dfs = []\n",
    "        for m in df[\"Year-Month\"].unique():\n",
    "            \n",
    "            month_df = df[(df[\"Year-Month\"].isin([m]))].sort_values(by='StartTime', ascending=True).reset_index(drop=True)\n",
    "\n",
    "            train_df = month_df[0:int(len(month_df)*(1-p))]\n",
    "            train_df = train_df.reset_index(drop=True)\n",
    "            valid_df = month_df[int(len(month_df)*(1-p)):]\n",
    "            valid_df = valid_df.reset_index(drop=True)\n",
    "            assert len(train_df)+len(valid_df) == len(month_df)\n",
    "            tarain_dfs.append(train_df)\n",
    "            valid_dfs.append(valid_df)\n",
    "        \n",
    "        t_df = pd.concat(tarain_dfs, ignore_index=True).sort_values(by='StartTime', ascending=True).reset_index(drop=True)\n",
    "        v_df = pd.concat(valid_dfs, ignore_index=True).sort_values(by='StartTime', ascending=True).reset_index(drop=True)\n",
    "\n",
    "        assert len(t_df)+len(v_df) == len(df) \n",
    "\n",
    "        return t_df, v_df\n",
    "    \n",
    "    def writeSequeces2TokenFile(self,file_path,li_of_seqs):\n",
    "        with open(file_path,\"w\") as f:\n",
    "            for seq in li_of_seqs:\n",
    "                f.write(f\"{' '.join(seq)}\\n\")\n",
    "        \n",
    "        print(\"Done\")\n",
    "\n",
    "\n",
    "def getCol2Count(df,col):\n",
    "    return dict(df[col].value_counts())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'file-path': \"../.data/all-months-alarms.csv\",\n",
    "    'usecols':[\"SourceName\", \"Condition\", \"StartTime\",\"EndTime\",\"TimeDelta\",\"Year-Month\"],\n",
    "    'date-cols':   [\"StartTime\", \"EndTime\"],\n",
    "    'alias': True\n",
    "}\n",
    "\n",
    "alarm = AlarmsProcessing(config=config)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "print(\"Total Time to load the data \", time.time()-start)\n",
    "\n",
    "\n",
    "alarm.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con2count=getCol2Count(df=alarm.df,col='Condition')\n",
    "con2count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove communication alarms\n",
    "df = alarm.removeConditionsAlarms(df=alarm.df,conditions_filter=[\"IOP\", \"IOP-\",'VEL+','VEL-'])\n",
    "con2count=getCol2Count(df=df,col='Condition')\n",
    "con2count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = alarm.removeChatteringAlarms(df=df,chattering_timedelta_threshold=60,chattering_count_threshold=2)\n",
    "con2count=getCol2Count(df=df,col='Condition')\n",
    "con2count\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "for cond,count in getCol2Count(df=df,col='Condition').items(): \n",
    "    l = df[df['Condition']==cond][\"SourceName\"].unique()\n",
    "    total += len(l)\n",
    "\n",
    "    print(f\">>{cond},{count},{len(l)}\")\n",
    "\n",
    "\n",
    "print(len(getCol2Count(df,col='SourceName')),total)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = alarm.removeSourcesBasedOnMinCount(df,min_alarms_per_source_filter=70)\n",
    "total = 0\n",
    "for cond,count in getCol2Count(df=df2,col='Condition').items(): \n",
    "    l = df2[df2['Condition']==cond][\"SourceName\"].unique()\n",
    "    total += len(l)\n",
    "\n",
    "    print(f\">>{cond},{count},{len(l)}\")\n",
    "\n",
    "\n",
    "print(len(getCol2Count(df2,col='SourceName')),total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_sources = []\n",
    "\n",
    "for s in df[\"SourceName\"].unique():\n",
    "    # print(len(df2[df2['SourceName']==s]['Condition'].unique()))\n",
    "    if len(df[df['SourceName']==s]['Condition'].unique())==1:\n",
    "        temp_sources.append(s)\n",
    "\n",
    "\n",
    "print(temp_sources)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_DF = df2\n",
    "\n",
    "\n",
    "alarm_dataset = PrepareDataset({})\n",
    "train_df, valid_df = alarm_dataset.splitDFtoTrainValidDfsPerMonth(FINAL_DF,p=0.3)\n",
    "valid_df, test_df = alarm_dataset.splitDFtoTrainValidDfsPerMonth(valid_df,p=0.2)\n",
    "\n",
    "seqs_train, _  = alarm_dataset.getSequenceOfWholeData(train_df,seq_duration_gap=60*15,filter_short_seq=0)\n",
    "seqs_valid, _  = alarm_dataset.getSequenceOfWholeData(valid_df,seq_duration_gap=60*15,filter_short_seq=0)\n",
    "seqs_test, _  = alarm_dataset.getSequenceOfWholeData(test_df,seq_duration_gap=60*15,filter_short_seq=0)\n",
    "\n",
    "alarm_dataset.writeSequeces2TokenFile(file_path=\"../.data/train.tokens\",li_of_seqs=seqs_train)\n",
    "alarm_dataset.writeSequeces2TokenFile(file_path=\"../.data/val.tokens\",li_of_seqs=seqs_valid)\n",
    "alarm_dataset.writeSequeces2TokenFile(file_path=\"../.data/test.tokens\",li_of_seqs=seqs_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duration_from_1_seq_to_next = 60*15 # duration in seconds\n",
    "# filter_short_seq = 3 # remove the sequence whose size is less than 4\n",
    "# li_of_seqs,max_seq_len = getSequenceOfWholeData(df_rnn,duration_from_1_seq_to_next,filter_short_seq)\n",
    "# print(len(li_of_seqs))\n",
    "# print(li_of_seqs[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq_len_2_count ={}\n",
    "# for seq in li_of_seqs:\n",
    "#     # seq = removeSameAlarms(seq)\n",
    "#     l = len(seq)\n",
    "#     seq_len_2_count[l] = 1+seq_len_2_count.get(l,0)\n",
    "\n",
    "# seq_len_2_count = {k:v for k,v in sorted(seq_len_2_count.items(), key=lambda t: t[1] )}\n",
    "# seq_len_2_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def removeSameAlarms(seq):\n",
    "#     new_seq = []\n",
    "\n",
    "#     new_seq.append(seq[0])\n",
    "\n",
    "#     for a in seq:\n",
    "\n",
    "#         if a == new_seq[-1]:\n",
    "#             continue\n",
    "#         new_seq.append(a)\n",
    "    \n",
    "#     return new_seq\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"DataSet is complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum(seq_len_2_count.keys())/len(seq_len_2_count.keys())\n",
    "# l = 5*['5']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
