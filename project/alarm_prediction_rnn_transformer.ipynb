{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Definition\n",
    "Recurrent Neural Networks (RNNs)  have shown a lot of potential in many natural language processing (NLP) and sequence learning tasks. The main idea behind sequential learning is that they make use of sequential information. In traditional feed-forward neural networks such as Convolutional Neural Networks (CNNs), it is assumed that all inputs are independent of each other, e.g., in an image classification task, the pixels of an image are independent of each other. However, this approach is not valid for sequence learning tasks. For instance, if you want to predict the next word in a sequence (sentence), you need the prior information (i.e., previous words in the sentence) to do so. RNNs can remember previous states (information), i.e., RNNs have a “memory” in the form of hidden states which store information about what has been processed so far. At each input of the sequence, the model not only takes the current input but also remembers the preceding information. Like the human way of processing sequential information, this allows the model to learn long-term dependencies in the sequence, i.e., it considers the entire context when making a prediction. \n",
    "\n",
    "Prediction of the next alarm can also be modelled as a sequence learning task: given a sorted sequence of alarms based on their start time, predict the upcoming alarm. In this report, we compared a RNN architecture and a Transfomrer architecture in terms of accuracy of predicitng next alarm. \n",
    "\n",
    "By predicting future alarms in real-time with the help of the AI module, the operator may avert abnormal situations by taking corrective actions or prepare for such situations in advance.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "42"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # for logging \n",
    "\n",
    "from comet_ml import Experiment\n",
    "from pytorch_lightning.loggers import CometLogger\n",
    "from pytorch_lightning.loggers import TestTubeLogger\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import wandb\n",
    "\n",
    "# For metrics\n",
    "from pytorch_lightning import metrics\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import io\n",
    "import torchtext\n",
    "from torchtext.utils import download_from_url, extract_archive\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.trainer.trainer import Trainer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping # The EarlyStopping callback can be used to monitor a validation metric and stop the training when no improvement is observed.\n",
    "\"\"\"\n",
    "    To enable it:\n",
    "\n",
    "    Import EarlyStopping callback.\n",
    "\n",
    "    Log the metric you want to monitor using log() method.\n",
    "\n",
    "    Init the callback, and set monitor to the logged metric of your choice.\n",
    "\n",
    "    Pass the EarlyStopping callback to the Trainer callbacks flag.\n",
    "\"\"\"\n",
    "\n",
    "from pytorch_lightning import seed_everything\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.metrics import Metric\n",
    "from pytorch_lightning.metrics.utils import _input_format_classification\n",
    "from sklearn.metrics import classification_report\n",
    "class MyClassificationReport(Metric):\n",
    "    def __init__(self,threshold: float = 0.5,compute_on_step: bool = True,dist_sync_on_step: bool = False):\n",
    "        super().__init__(\n",
    "            compute_on_step=compute_on_step,\n",
    "            dist_sync_on_step=dist_sync_on_step,\n",
    "        )\n",
    "\n",
    "        self.threshold = threshold\n",
    "        self.add_state(\"preds\", default=[], dist_reduce_fx=None)\n",
    "        self.add_state(\"target\", default=[], dist_reduce_fx=None)\n",
    "\n",
    "        # rank_zero_warn(\n",
    "        #     'Metric `MyClassificationReport` will save all targets and predictions in buffer.'\n",
    "        #     ' For large datasets this may lead to large memory footprint.'\n",
    "        # )\n",
    "\n",
    "    def update(self, preds: torch.Tensor, target: torch.Tensor):\n",
    "        preds = preds.cpu()\n",
    "        target = target.cpu()\n",
    "        y_hat, y = preds.max(1).indices, target\n",
    "        assert y_hat.shape == y.shape\n",
    "        self.preds.append(y_hat)\n",
    "        self.target.append(y)\n",
    "\n",
    "    def compute(self):\n",
    "        preds = torch.cat(self.preds, dim=0)\n",
    "        target = torch.cat(self.target, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Prepartion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class AlarmDataset(Dataset):\n",
    "    def __init__(self,data,seq_len,batch_size):\n",
    "        self.length = len(data)//seq_len # how much data i have         \n",
    "        self.data = data\n",
    "        self.seq_len = seq_len\n",
    "        self.batch_size = batch_size\n",
    "       \n",
    "    def __getitem__(self, index: int):\n",
    "        x = self.data[index*self.seq_len:(index*self.seq_len)+self.seq_len]\n",
    "        y = self.data[1+index*self.seq_len:1+(index*self.seq_len)+self.seq_len]\n",
    "        return x,y\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return self.length\n",
    "\n",
    "class MyDataModule(pl.LightningDataModule):\n",
    "    \n",
    "    def __init__(self,config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        dir_path = self.config['dir-path']\n",
    "        file_name = 'train.tokens'\n",
    "\n",
    "        self.tokenizer = get_tokenizer('basic_english')\n",
    "        self.vocab = build_vocab_from_iterator(map(self.tokenizer,iter(io.open(dir_path+file_name,encoding=\"utf8\"))))\n",
    "    \n",
    "\n",
    "        train_data = self.data_process(iter(io.open(dir_path +\"train.tokens\", encoding=\"utf8\")))\n",
    "        val_data = self.data_process(iter(io.open(dir_path +\"val.tokens\", encoding=\"utf8\")))\n",
    "        test_data = self.data_process(iter(io.open(dir_path +\"test.tokens\", encoding=\"utf8\")))\n",
    "\n",
    "    \n",
    "        self.train_dataset = AlarmDataset(train_data, self.config['seq-len'], self.config['batch-size'])\n",
    "        self.valid_dataset = AlarmDataset(val_data,self.config['seq-len'], self.config['batch-size'])\n",
    "        self.test_dataset = AlarmDataset(test_data, self.config['seq-len'], self.config['batch-size'])\n",
    "\n",
    "    \n",
    "    def data_process(self, raw_text_iter):\n",
    "        data = [torch.tensor([self.vocab[token] for token in self.tokenizer(item)],dtype=torch.long) for item in raw_text_iter]\n",
    "        return torch.cat(tuple(filter(lambda t: t.numel() > 0, data)))\n",
    "    \n",
    "    def get_weight_per_class(self):\n",
    "        def lambdaFun(total,v,num_classes):\n",
    "            if v>0:\n",
    "                return total/(v*num_classes) \n",
    "            return 0\n",
    "        \n",
    "        index_2_count = {self.vocab.stoi[k]:self.vocab.freqs[k]  for k in list(self.vocab.stoi)}\n",
    "        total = sum(index_2_count.values())\n",
    "        index_2_ws = {k:lambdaFun(total,v,len(index_2_count)) for k,v in index_2_count.items()}\n",
    "        index_2_ws[1] = 0.0 # MANUALLY Setting the weights to zero for the padding\n",
    "        # index_2_ws[0] = 0.0 # MANUALLY Setting the weights to zero for the padding\n",
    "        ws = torch.tensor([index_2_ws[i] for i in range(len(index_2_ws))])\n",
    "\n",
    "        return ws\n",
    "\n",
    "    def prepare_data(self):\n",
    "        \"\"\"\n",
    "            Use this method to do things that might write to disk or that need to be done only from a single GPU in distributed settings.\n",
    "            e.g., download,tokenize,etc…\n",
    "        \"\"\" \n",
    "        return None\n",
    "\n",
    "\n",
    "    def setup(self, stage: None):\n",
    "        \"\"\"\n",
    "            There are also data operations you might want to perform on every GPU. Use setup to do things like:\n",
    "            count number of classes,build vocabulary,perform train/val/test splits,apply transforms (defined explicitly in your datamodule or assigned in init),etc…\n",
    "        \"\"\"\n",
    "        return None\n",
    "\n",
    "    def train_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(self.train_dataset, batch_size=self.config['batch-size'], shuffle=False,num_workers=8,drop_last=True, pin_memory=True)\n",
    "    \n",
    "    def val_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(self.valid_dataset, batch_size=self.config['batch-size'], shuffle=False,num_workers=8,drop_last=True, pin_memory=True)\n",
    "    \n",
    "    def test_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(self.test_dataset, batch_size=self.config['batch-size'], shuffle=False,num_workers=8,drop_last=True, pin_memory=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Model\n",
    "\n",
    "The alarm modeling task is to assign a\n",
    "probability for the likelihood of a given sequence of words\n",
    "to follow a next alarm. A sequence of tokens are passed to the embedding\n",
    "layer first, followed by a positional encoding layer to account for the order\n",
    "of the word. The\n",
    "``nn.TransformerEncoder`` consists of multiple layers of\n",
    "`nn.TransformerEncoderLayer <https://pytorch.org/docs/master/nn.html?highlight=transformerencoderlayer#torch.nn.TransformerEncoderLayer>`__. Along with the input sequence, a square\n",
    "attention mask is required because the self-attention layers in\n",
    "``nn.TransformerEncoder`` are only allowed to attend the earlier positions in\n",
    "the sequence. For the language modeling task, any tokens on the future\n",
    "positions should be masked. To have the actual alarms, the output\n",
    "of ``nn.TransformerEncoder`` model is sent to the final Linear\n",
    "layer, which is followed by a log-Softmax function.\n",
    "\n",
    "\n",
    "# Positional Encoding\n",
    "\n",
    "``PositionalEncoding`` module injects some information about the\n",
    "relative or absolute position of the tokens (i.e.,) in the sequence. The\n",
    "positional encodings have the same dimension as the embeddings so that\n",
    "the two can be summed. Here, we use ``sine`` and ``cosine`` functions of\n",
    "different frequencies.\n",
    "\n",
    "# Loss Function\n",
    "\n",
    "`CrossEntropyLoss` is applied to track the loss and `AdamW`implements stochastic gradient descent method as the optimizer.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.accuraccy_50_count = 0\n",
    "        self.config = config        \n",
    "        self.lr = self.config[\"lr\"]\n",
    "        self.weight_decay = self.config[\"weight-decay\"]\n",
    "    \n",
    "        self.pos_encoder = PositionalEncoding(self.config['em-size'], self.config['dropout'])\n",
    "        encoder_layers = torch.nn.TransformerEncoderLayer(self.config['em-size'], self.config['nhead'], self.config['nhid'], self.config[\"dropout\"])\n",
    "        self.transformer_encoder = torch.nn.TransformerEncoder(encoder_layers, self.config['nlayers'])\n",
    "        self.encoder = torch.nn.Embedding(self.config[\"vocab-size\"], self.config['em-size'])\n",
    "        self.decoder = torch.nn.Linear(self.config['em-size'], self.config[\"vocab-size\"])\n",
    "        self.src_mask = self.generate_square_subsequent_mask(self.config['seq-len'])\n",
    "        self.init_weights()\n",
    "\n",
    "        self.class_weight = self.config['weight_per_class']\n",
    "\n",
    "        # self.train_F1 = metrics.classification.F1(num_classes=self.config[\"vocab-size\"],average = 'micro')\n",
    "        # self.val_F1 = metrics.classification.F1(num_classes=self.config[\"vocab-size\"],average = 'micro')\n",
    "        # self.test_F1 = metrics.classification.F1(num_classes=self.config[\"vocab-size\"],average = 'micro')\n",
    "        \n",
    "        self.val_CM_normalized = metrics.classification.ConfusionMatrix(num_classes=self.config[\"vocab-size\"],normalize ='true')\n",
    "        self.val_CM_raw = metrics.classification.ConfusionMatrix(num_classes=self.config[\"vocab-size\"])\n",
    "\n",
    "        self.train_CM_normalized = metrics.classification.ConfusionMatrix(num_classes=self.config[\"vocab-size\"],normalize ='true')\n",
    "        self.train_CM_raw = metrics.classification.ConfusionMatrix(num_classes=self.config[\"vocab-size\"])\n",
    "\n",
    "        self.test_CM = metrics.classification.ConfusionMatrix(num_classes=self.config[\"vocab-size\"],normalize ='true')\n",
    "\n",
    "        self.val_MCR = MyClassificationReport()\n",
    "        self.test_MCR = MyClassificationReport()\n",
    "\n",
    "        self.log(\"Sequence length\",self.config['seq-len'])\n",
    "        self.log(\"lr\",self.lr)\n",
    "        self.log(\"# of tokens/vocab_size (unique alarms)\",self.config['vocab-size'])\n",
    "        self.log(\"weight_decay\",self.weight_decay)\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src, src_mask):\n",
    "        src_mask = src_mask.to(self.device)\n",
    "        src = self.encoder(src) * math.sqrt(self.config['em-size'])\n",
    "        src = self.pos_encoder(src)\n",
    "        src_mask = src_mask.to(self.device)\n",
    "      \n",
    "        output = self.transformer_encoder(src, src_mask)\n",
    "        output = self.decoder(output)\n",
    "        \n",
    "        return output\n",
    "\n",
    "   # The ReduceLROnPlateau scheduler requires a monitor\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr,weight_decay=self.weight_decay)\n",
    "        d = {\n",
    "       'optimizer': optimizer,\n",
    "       'lr_scheduler': torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode = \"min\", factor = 0.5, patience=10, verbose=True),\n",
    "       'monitor': 'val_epoch_loss',\n",
    "        'interval': 'epoch'\n",
    "        }\n",
    "        return d \n",
    "\n",
    "    def loss_function(self,logits,y):\n",
    "        return F.cross_entropy(logits,y,weight= self.class_weight,ignore_index=1) \n",
    "\n",
    "    def myPrintToFile(self,cm_normal,cm_raw,f):\n",
    "        cm_normal = cm_normal.cpu()\n",
    "        cm_raw = cm_raw.cpu()\n",
    "        \n",
    "\n",
    "        sum_of_each_class = cm_raw.sum(axis=1) # sum along the columns\n",
    "        print(f\"        ------ Epoch {self.current_epoch} ---------\",file=f)\n",
    "        print(f\"Total={[v.item() for v in sum_of_each_class]}\",file=f)\n",
    "        print(f\"Corret={[v.item() for v in torch.diagonal(cm_raw,0)]}\",file=f)\n",
    "        print(f\"Accuracy={[round(v.item(),3) for v in (torch.diagonal(cm_raw,0)/sum_of_each_class)]}\",file=f)\n",
    "\n",
    "        accs = [round(v.item(),3)  for v in torch.diagonal(cm_normal,0)]\n",
    "\n",
    "        source2acc = {self.config['vocab'].itos[i]:accs[i] for i in range(len(accs))}\n",
    "\n",
    "        source2_acc50 = {self.config['vocab'].itos[i]:accs[i] for i in range(len(accs)) if accs[i]>=0.5}\n",
    "\n",
    "        print(f\"Acc2={accs}\",file=f)\n",
    "        print(f\"source2_acc= {source2acc}\",file=f)\n",
    "        print(f\"source2_acc50= {source2_acc50}\",file=f)\n",
    "\n",
    "        a_50 = len([a for a in accs if a>=0.5])\n",
    "        a_30 = len([a for a in accs if a>=0.3])\n",
    "        out_str = f\"acc>0.5= {a_50}, acc>=0.3= {a_30}, Total={len(accs)}\"\n",
    "        print(out_str,file=f)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        # if temp> self.accuraccy_50_count and train=:\n",
    "        #     self.accuraccy_50_count = temp\n",
    "        print(out_str,end=\" \") \n",
    "\n",
    "      \n",
    "\n",
    "    def training_step(self,batch,batch_idx):\n",
    "        x,y = batch\n",
    "        x = x.T\n",
    "        y = y.T.reshape(-1)\n",
    "\n",
    "        if x.size(0) != self.config['seq-len']:\n",
    "           self.src_mask =  self.generate_square_subsequent_mask(x.size(0))\n",
    "        \n",
    "        y_hat = self(x,self.src_mask)\n",
    "        y_hat =  y_hat.view(-1, self.config['vocab-size'])\n",
    "        loss = self.loss_function(y_hat,y) # cross entropy itself compute softmax \n",
    "\n",
    "        self.train_CM_normalized(F.softmax(y_hat),y)\n",
    "        self.train_CM_raw(F.softmax(y_hat),y)\n",
    "        \n",
    "        self.log('train_loss',loss,logger=True)\n",
    "        # self.log('train_F1',self.train_F1(F.softmax(y_hat),y),logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self,batch, batch_idx):\n",
    "        x,y = batch\n",
    "        x = x.T\n",
    "        y = y.T.reshape(-1)\n",
    "        \n",
    "        if x.size(0) != self.config['seq-len']:\n",
    "            # print(f\">> passed {x.size()}\")\n",
    "            self.src_mask =  self.generate_square_subsequent_mask(x.size(0))\n",
    "        \n",
    "        y_hat = self(x,self.src_mask)\n",
    "        y_hat =  y_hat.view(-1, self.config['vocab-size'])\n",
    "        loss = self.loss_function(y_hat,y)\n",
    "\n",
    "        self.val_MCR(F.softmax(y_hat),y)\n",
    "        self.val_CM_normalized(F.softmax(y_hat),y)\n",
    "        self.val_CM_raw(F.softmax(y_hat),y)\n",
    "\n",
    "        self.log('val_loss',loss,logger=True)\n",
    "        # self.log('val_F1',self.val_F1(F.softmax(y_hat) ,y),logger=True)\n",
    "        return {'val_loss':loss}\n",
    "    \n",
    "    def test_step(self,batch, batch_idx):\n",
    "        x,y = batch\n",
    "        x = x.T\n",
    "        y = y.T.reshape(-1)\n",
    "        if x.size(0) != self.config['seq-len']:\n",
    "           self.src_mask =  self.generate_square_subsequent_mask(x.size(0))\n",
    "\n",
    "        y_hat = self(x,self.src_mask)\n",
    "        y_hat =  y_hat.view(-1,  self.config['vocab-size'])\n",
    "        loss = self.loss_function(y_hat,y)\n",
    "\n",
    "        self.test_MCR(F.softmax(y_hat),y)\n",
    "        self.log('test_loss',loss,logger=True)\n",
    "        # self.log('test_F1', self.test_F1(F.softmax(y_hat) ,y),logger=True)\n",
    "        return {'test_loss':loss}\n",
    "    \n",
    "    def training_epoch_end(self, outputs):\n",
    "\n",
    "        avg_loss = torch.stack([d['loss']  for d in outputs]).mean()\n",
    "        # f1 = self.train_F1.compute()\n",
    "        print(f\"[{self.current_epoch}]E, Avg Training loss = {round(avg_loss.item(),4)}\",end=\" \")\n",
    "        \n",
    "        with open(self.config[\"train-file\"],'a') as f:\n",
    "            self.myPrintToFile(self.train_CM_normalized.compute(),self.train_CM_raw.compute(),f)\n",
    "        self.log(\"train_epoch_loss\",avg_loss,logger=True,prog_bar=True)\n",
    "        # self.log(\"train_epoch_F1\", f1, logger=True,prog_bar=True)\n",
    "  \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([d['val_loss'] for d in outputs]).mean()\n",
    "        # f1 = self.val_F1.compute()\n",
    "        # print(self.val_MCR.compute(),file=open(\"val-out.txt\",'w'))\n",
    "        # print(self.val_CM.compute(),file=open(\"val-cm-out.txt\",'w'))\n",
    "\n",
    "        # if self.current_epoch%4==0 and self.current_epoch>0:\n",
    "        # self.myPrintToFile(self.val_CM_normalized.compute(),self.val_CM_raw.compute())\n",
    "\n",
    "\n",
    "        print(f\"::Val Loss = {round(avg_loss.item(),4) }\",end=\" \")\n",
    "\n",
    "        with open(self.config[\"val-file\"],'a') as f:\n",
    "            self.myPrintToFile(self.val_CM_normalized.compute(),self.val_CM_raw.compute(),f)\n",
    "        \n",
    "        print(\"\")\n",
    "\n",
    "\n",
    "        self.log(\"val_epoch_loss\",avg_loss,logger=True)\n",
    "        # self.log(\"val_epoch_F1\",f1,logger=True,prog_bar=True)\n",
    "    \n",
    "    def test_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([d['test_loss'] for d in outputs]).mean()\n",
    "        # f1 = self.test_F1.compute()\n",
    "        # print(self.test_MCR.compute(),file=open(\"test-out.txt\",'w'))\n",
    "        print(f\">Average Test Loss = {avg_loss.item()}\")\n",
    "        self.log(\"test_epoch_loss\",avg_loss, logger = True)\n",
    "        # self.log(\"test_epoch_F1\",f1, logger=True)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlarmGRU(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self,config):\n",
    "        # super().__init__()\n",
    "        super(AlarmGRU,self).__init__()\n",
    "        self.config =config\n",
    "        self.lr = self.config['lr']\n",
    "        \n",
    "\n",
    "        self.val_CM_normalized = metrics.classification.ConfusionMatrix(num_classes=self.config[\"vocab-size\"],normalize ='true')\n",
    "        self.val_CM_raw = metrics.classification.ConfusionMatrix(num_classes=self.config[\"vocab-size\"])\n",
    "\n",
    "        self.train_CM_normalized = metrics.classification.ConfusionMatrix(num_classes=self.config[\"vocab-size\"],normalize ='true')\n",
    "        self.train_CM_raw = metrics.classification.ConfusionMatrix(num_classes=self.config[\"vocab-size\"])\n",
    "\n",
    "        self.test_CM = metrics.classification.ConfusionMatrix(num_classes=self.config[\"vocab-size\"],normalize ='true')\n",
    "\n",
    "        self.val_MCR = MyClassificationReport()\n",
    "        self.test_MCR = MyClassificationReport()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ## TODO: define the layers of the model\n",
    "        self.h = None\n",
    "        self.embedding = torch.nn.Embedding(self.config['vocab-size'],self.config['em-size'])\n",
    "        self.gru = torch.nn.GRU(input_size=self.config['em-size'], hidden_size=self.config['nhid'], num_layers=self.config['nlayers'],dropout=self.config['dropout'], batch_first=True)\n",
    "        # self.droput = torch.nn.Dropout(p=self.drop_prob)\n",
    "        self.fc3 = torch.nn.Linear(in_features=self.config['nhid'], out_features=self.config['vocab-size'])\n",
    "        self.softmax = torch.nn.LogSoftmax(dim=1)  \n",
    "    \n",
    "    def __init_hidden(self):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n",
    "        # initialized to zero, for hidden state and cell state of GRU\n",
    "        device = None \n",
    "        if (torch.cuda.is_available()):\n",
    "            device = torch.device(\"cuda\")\n",
    "        else:\n",
    "            device = torch.device(\"cpu\") \n",
    "        \n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = weight.new(self.config['nlayers'], self.config['batch-size'], self.config['nhid']).zero_().to(device)\n",
    "        return hidden\n",
    "\n",
    "    def initialize_hidden(self):\n",
    "        self.h = self.__init_hidden()\n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        ''' Forward pass through the network. \n",
    "            These inputs are x, and the hidden/cell state `hidden`. '''\n",
    "                \n",
    "        ## TODO: Get the outputs and the new hidden state from the lstm\n",
    "        x = x.long()\n",
    "        embeds = self.embedding(x)\n",
    "        out, hidden = self.gru(embeds,hidden)\n",
    "        # Contiguous variables: If you are stacking up multiple LSTM outputs, it may be necessary to use .contiguous() to reshape the output.\n",
    "        out = out.contiguous().view(-1,self.config['nhid']) \n",
    "        out = self.fc3(out)\n",
    "        out = self.softmax(out)\n",
    "        # return the final output and the hidden state\n",
    "        return out, hidden\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr,weight_decay=self.config['weight-decay'])\n",
    "        d = {\n",
    "       'optimizer': optimizer,\n",
    "       'lr_scheduler': torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode = \"min\", factor = 0.5, patience=10, verbose=True),\n",
    "       'monitor': 'val_epoch_loss',\n",
    "        'interval': 'epoch'\n",
    "        }\n",
    "        return d\n",
    "\n",
    "    # def loss_function(self,logits,y):\n",
    "    #     return F.cross_entropy(logits,y,weight= self.class_weight,ignore_index=1) \n",
    "\n",
    "    def myPrintToFile(self,cm_normal,cm_raw,f):\n",
    "        cm_normal = cm_normal.cpu()\n",
    "        cm_raw = cm_raw.cpu()\n",
    "        \n",
    "\n",
    "        sum_of_each_class = cm_raw.sum(axis=1) # sum along the columns\n",
    "        print(f\"        ------ Epoch {self.current_epoch} ---------\",file=f)\n",
    "        print(f\"Total={[v.item() for v in sum_of_each_class]}\",file=f)\n",
    "        print(f\"Corret={[v.item() for v in torch.diagonal(cm_raw,0)]}\",file=f)\n",
    "        print(f\"Accuracy={[round(v.item(),3) for v in (torch.diagonal(cm_raw,0)/sum_of_each_class)]}\",file=f)\n",
    "\n",
    "        accs = [round(v.item(),3)  for v in torch.diagonal(cm_normal,0)]\n",
    "\n",
    "        source2acc = {self.config['vocab'].itos[i]:accs[i] for i in range(len(accs))}\n",
    "\n",
    "        source2_acc50 = {self.config['vocab'].itos[i]:accs[i] for i in range(len(accs)) if accs[i]>=0.5}\n",
    "\n",
    "        print(f\"Acc2={accs}\",file=f)\n",
    "        print(f\"source2_acc= {source2acc}\",file=f)\n",
    "        print(f\"source2_acc50= {source2_acc50}\",file=f)\n",
    "\n",
    "        a_50 = len([a for a in accs if a>=0.5])\n",
    "        a_30 = len([a for a in accs if a>=0.3])\n",
    "        out_str = f\"acc>0.5= {a_50}, acc>=0.3= {a_30}, Total={len(accs)}\"\n",
    "        print(out_str,file=f)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        # if temp> self.accuraccy_50_count and train=:\n",
    "        #     self.accuraccy_50_count = temp\n",
    "        print(out_str,end=\" \")\n",
    "    \n",
    "    \n",
    "    def training_step(self,batch,batch_idx):\n",
    "        x,y = batch\n",
    "        y =  y.view(self.config['batch-size']*self.config['seq-len']).long()\n",
    "\n",
    "        self.h = self.h.data # for GRU\n",
    "        y_hat, self.h = self(x,self.h)\n",
    "        #  ignore_index=self.char2int[\"NoName\"]\n",
    "        loss = F.nll_loss(y_hat,y)\n",
    "        \n",
    "        self.train_CM_normalized(y_hat,y)\n",
    "        self.train_CM_raw(y_hat,y)    \n",
    "        # result = pl.TrainResult(loss) # logging\n",
    "        self.log('train_loss',loss,logger=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self,batch, batch_idx):\n",
    "        x,y = batch\n",
    "        y =  y.view(self.config['batch-size']*self.config['seq-len']).long()\n",
    "\n",
    "        self.h = self.h.data # for GRU\n",
    "        y_hat, self.h = self(x,self.h)\n",
    "        #  ignore_index=self.char2int[\"NoName\"]\n",
    "        loss = F.nll_loss(y_hat,y)\n",
    "        \n",
    "        self.val_CM_normalized(y_hat,y)\n",
    "        self.val_CM_raw(y_hat,y)\n",
    "        self.log('val_loss',loss,logger=True)\n",
    "        return {'val_loss':loss}\n",
    "    \n",
    "    def test_step(self,batch, batch_idx):\n",
    "        x,y = batch\n",
    "        y =  y.view(self.config['batch-size']*self.config['seq-len']).long()\n",
    "\n",
    "        self.h = self.h.data # for GRU\n",
    "        y_hat, self.h = self(x,self.h)\n",
    "        #  ignore_index=self.char2int[\"NoName\"]\n",
    "        loss = F.nll_loss(y_hat,y)\n",
    "        \n",
    "        self.val_CM_normalized(y_hat,y)\n",
    "        self.val_CM_raw(y_hat,y)\n",
    "        self.log('test_loss',loss,logger=True)\n",
    "        return {'test_loss':loss}\n",
    "    \n",
    "    def training_epoch_end(self, outputs):\n",
    "\n",
    "        avg_loss = torch.stack([d['loss']  for d in outputs]).mean()\n",
    "        # f1 = self.train_F1.compute()\n",
    "        print(f\"[{self.current_epoch}]E, Avg Training loss = {round(avg_loss.item(),4)}\",end=\" \")\n",
    "        \n",
    "        with open(self.config[\"train-file\"],'a') as f:\n",
    "            self.myPrintToFile(self.train_CM_normalized.compute(),self.train_CM_raw.compute(),f)\n",
    "        self.log(\"train_epoch_loss\",avg_loss,logger=True,prog_bar=True)\n",
    "        # self.log(\"train_epoch_F1\", f1, logger=True,prog_bar=True)\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([d['val_loss'] for d in outputs]).mean()\n",
    "        # f1 = self.val_F1.compute()\n",
    "        # print(self.val_MCR.compute(),file=open(\"val-out.txt\",'w'))\n",
    "        # print(self.val_CM.compute(),file=open(\"val-cm-out.txt\",'w'))\n",
    "\n",
    "        # if self.current_epoch%4==0 and self.current_epoch>0:\n",
    "        # self.myPrintToFile(self.val_CM_normalized.compute(),self.val_CM_raw.compute())\n",
    "\n",
    "\n",
    "        print(f\"::Val Loss = {round(avg_loss.item(),4) }\",end=\" \")\n",
    "\n",
    "        with open(self.config[\"val-file\"],'a') as f:\n",
    "            self.myPrintToFile(self.val_CM_normalized.compute(),self.val_CM_raw.compute(),f)\n",
    "        \n",
    "        print(\"\")\n",
    "\n",
    "\n",
    "        self.log(\"val_epoch_loss\",avg_loss,logger=True)\n",
    "        # self.log(\"val_epoch_F1\",f1,logger=True,prog_bar=True)\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([d['test_loss'] for d in outputs]).mean()\n",
    "        # f1 = self.test_F1.compute()\n",
    "        # print(self.test_MCR.compute(),file=open(\"test-out.txt\",'w'))\n",
    "        print(f\">Average Test Loss = {avg_loss.item()}\")\n",
    "        self.log(\"test_epoch_loss\",avg_loss, logger = True)\n",
    "        # self.log(\"test_epoch_F1\",f1, logger=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainning Transformers\n",
    "\n",
    "**Note: When monitoring any parameter after the validation epoch end then you should pass check_val_every_n_epoch=1  not to other. This is very important.**\n",
    "\n",
    "### Finding the learning rate for the Transformer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48716lines [00:00, 80783.68lines/s]\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Using native 16bit precision.\n",
      "\n",
      "   | Name                | Type                   | Params\n",
      "----------------------------------------------------------------\n",
      "0  | pos_encoder         | PositionalEncoding     | 0     \n",
      "1  | transformer_encoder | TransformerEncoder     | 1.3 M \n",
      "2  | encoder             | Embedding              | 186 K \n",
      "3  | decoder             | Linear                 | 186 K \n",
      "4  | val_CM_normalized   | ConfusionMatrix        | 0     \n",
      "5  | val_CM_raw          | ConfusionMatrix        | 0     \n",
      "6  | train_CM_normalized | ConfusionMatrix        | 0     \n",
      "7  | train_CM_raw        | ConfusionMatrix        | 0     \n",
      "8  | test_CM             | ConfusionMatrix        | 0     \n",
      "9  | val_MCR             | MyClassificationReport | 0     \n",
      "10 | test_MCR            | MyClassificationReport | 0     \n",
      "----------------------------------------------------------------\n",
      "1.7 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.7 M     Total params\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before [0.0, 0.0, 0.008, 0.008, 0.059, 0.059, 0.065, 0.072, 0.074, 0.074, 0.082, 0.082, 0.083, 0.084, 0.095, 0.107, 0.129, 0.156, 0.172, 0.174, 0.175, 0.18, 0.186, 0.205, 0.219, 0.25, 0.279, 0.312, 0.328, 0.349, 0.358, 0.383, 0.393, 0.399, 0.405, 0.406, 0.409, 0.421, 0.426, 0.427, 0.427, 0.443, 0.458, 0.467, 0.469, 0.489, 0.491, 0.506, 0.512, 0.512, 0.521, 0.531, 0.537, 0.547, 0.556, 0.561, 0.566, 0.58, 0.59, 0.631, 0.633, 0.649, 0.659, 0.674, 0.69, 0.69, 0.697, 0.701, 0.705, 0.712, 0.723, 0.726, 0.731, 0.737, 0.747, 0.765, 0.765, 0.767, 0.809, 0.818, 0.836, 0.86, 0.865, 0.873, 0.878, 0.879, 0.884, 0.911, 0.927, 0.984, 0.987, 0.989, 0.998, 1.007, 1.016, 1.018, 1.028, 1.056, 1.069, 1.072, 1.076, 1.077, 1.1, 1.117, 1.129, 1.138, 1.144, 1.145, 1.147, 1.159, 1.166, 1.169, 1.172, 1.181, 1.201, 1.204, 1.215, 1.215, 1.224, 1.247, 1.247, 1.247, 1.247, 1.247, 1.247, 1.247, 1.247, 1.247, 1.25, 1.251, 1.271, 1.279, 1.285, 1.289, 1.296, 1.306, 1.314, 1.316, 1.323, 1.326, 1.347, 1.351, 1.354, 1.37, 1.386, 1.406, 1.407, 1.429, 1.442, 1.46, 1.497, 1.508, 1.53, 1.584, 1.584, 1.618, 1.635, 1.64, 1.642, 1.658, 1.688, 1.695, 1.697, 1.699, 1.706, 1.727, 1.736, 1.772, 1.808, 1.825, 1.829, 1.834, 1.866, 1.88, 1.903, 1.916, 1.919, 1.926, 1.931, 1.957, 1.999, 2.002, 2.007, 2.023, 2.044, 2.046, 2.081, 2.135, 2.141, 2.165, 2.251, 2.261, 2.278, 2.294, 2.301, 2.304, 2.396, 2.444, 2.448, 2.459, 2.479, 2.487, 2.543, 2.559, 2.559, 2.572, 2.58, 2.58, 2.65, 2.659, 2.776, 2.781, 2.781, 2.816, 2.852, 2.857, 2.868, 2.921, 2.948, 2.965, 2.976, 2.988, 2.993, 3.005, 3.046, 3.075, 3.075, 3.081, 3.087, 3.087, 3.093, 3.093, 3.1, 3.112, 3.124, 3.149, 3.156, 3.188, 3.227, 3.24, 3.247, 3.247, 3.26, 3.267, 3.288, 3.308, 3.372, 3.38, 3.387, 3.409, 3.484, 3.484, 3.492, 3.524, 3.555, 3.555, 3.563, 3.655, 3.751, 3.769, 3.778, 3.842, 3.89, 3.89, 3.989, 4.04, 4.05, 4.05, 4.082, 4.082, 4.135, 4.157, 4.168, 4.202, 4.259, 4.27, 4.282, 4.305, 4.317, 4.317, 4.365, 4.402, 4.464, 4.464, 4.464, 4.49, 4.516, 4.555, 4.595, 4.595, 4.595, 4.622, 4.649, 4.762, 4.791, 4.835, 4.85, 4.85, 4.926, 4.942, 4.989, 5.053, 5.086, 5.102, 5.169, 5.186, 5.186, 5.238, 5.291, 5.291, 5.327, 5.327, 5.4, 5.419, 5.438, 5.495, 5.533, 5.573, 5.573, 5.612, 5.633, 5.633, 5.653, 5.653, 5.673, 5.694, 5.714, 5.756, 5.778, 5.799, 5.82, 5.864, 5.864, 5.908, 5.953, 6.021, 6.044, 6.139, 6.163, 6.211, 6.211, 6.236, 6.236, 6.236, 6.286, 6.337, 6.362, 6.388, 6.521, 6.521, 6.548, 6.575, 6.631, 6.687, 6.716, 6.774, 6.833, 6.923, 6.923, 6.984, 7.047, 7.047, 7.047, 7.079, 7.079, 7.079, 7.111, 7.111, 7.176, 7.309, 7.378, 7.413, 7.413, 7.519, 7.555, 7.592, 7.666, 7.741, 7.741, 7.818, 7.818, 7.818, 7.977, 7.977, 7.977, 8.018, 8.059, 8.059, 8.1, 8.1, 8.185, 8.185, 8.185, 8.228, 8.228, 8.228, 8.359, 8.404, 8.449, 8.449, 8.541, 8.541, 8.541, 8.541, 8.587, 8.587, 8.635, 8.635, 8.635, 8.73, 8.73, 8.779, 8.829, 8.878, 8.929, 8.929, 8.98, 8.98, 9.084, 9.137, 9.19, 9.19, 9.299, 9.299, 9.41, 9.41, 9.41, 9.467, 9.701, 9.701, 9.761, 9.822, 9.884, 10.074, 10.074, 10.204, 10.204, 10.204, 10.271, 10.339, 10.339, 10.339, 10.407, 10.618, 10.618, 10.618, 10.838, 11.067, 11.067, 11.306, 11.388, 11.388, 11.388, 11.471, 11.641, 11.727, 11.727, 11.816, 11.905, 11.905, 12.088, 12.182, 12.182, 12.277, 12.277, 12.277, 12.277, 12.374, 12.472, 12.472, 12.572, 12.572, 12.673, 12.673, 12.673, 12.776, 12.881, 12.987, 12.987, 12.987, 12.987, 13.096, 13.096, 13.206, 13.318, 13.318, 13.431, 13.431, 13.547, 13.547, 13.785, 13.907, 13.907, 13.907, 13.907, 14.031, 14.031, 14.158, 14.158, 14.158, 14.417, 14.417, 14.551, 14.551, 14.551, 14.551, 14.551, 14.687, 14.687, 14.687, 14.687, 14.825, 14.967, 14.967, 14.967, 14.967, 14.967, 15.11, 15.11, 15.11, 15.11, 15.11, 15.11, 15.407, 15.407, 15.559, 15.559, 15.559, 15.559, 15.559, 15.559, 15.715, 15.715, 15.715, 15.874, 16.036, 16.036, 16.036, 16.201, 16.201, 16.201, 16.37, 16.37, 16.37, 16.37, 16.37, 16.542, 16.718, 16.718, 16.718, 16.718, 16.898, 16.898, 16.898, 16.898, 17.081, 17.081, 17.081, 17.081, 17.269, 17.269, 17.269, 17.269, 17.269, 17.461, 17.461, 17.461, 17.461, 17.461, 17.657, 17.657, 17.858, 17.858, 17.858, 17.858, 18.063, 18.063, 18.063, 18.063, 18.273, 18.273, 18.488, 18.708, 18.708, 18.934, 18.934, 18.934, 18.934, 18.934, 19.164, 19.164, 19.164, 19.401, 19.644, 19.644, 19.644, 19.644, 19.892, 19.892, 20.147, 20.409, 20.409, 20.409, 20.409, 20.677, 20.677, 20.677, 20.677, 20.953, 20.953, 21.236, 21.236, 21.236, 21.236, 21.527, 21.826, 21.826, 21.826, 21.826, 21.826, 21.826, 21.826, 22.134, 22.134, 22.134, 22.134, 22.45, 22.45, 23.11, 23.11, 23.11, 23.11, 23.455, 23.455, 23.455, 23.455, 23.81, 23.81, 23.81, 23.81, 23.81, 23.81, 23.81, 24.177, 24.177, 24.177, 24.177, 24.177, 24.177, 24.177, 24.554, 24.554, 24.554, 24.554, 24.944, 25.347, 25.347, 25.347, 25.762, 25.762, 25.762, 25.762, 26.191, 26.191, 26.635, 26.635, 26.635, 26.635, 26.635, 26.635, 26.635, 26.635, 26.635, 26.635, 26.635, 26.635, 26.635, 27.095, 27.095, 27.095, 27.095, 27.095, 27.57, 27.57, 27.57, 27.57, 27.57, 28.062, 28.062, 28.062, 28.062, 28.062, 28.572, 28.572, 29.651, 29.651, 29.651, 30.221, 30.221, 30.221, 30.221, 31.43, 31.43, 31.43, 31.43, 32.071, 32.071, 32.071, 32.739, 32.739, 33.436, 33.436, 34.163, 34.163, 34.163, 35.716, 38.329, 38.329, 40.294, 40.294, 40.294, 41.355, 43.652, 47.621, 54.189, 92.44, 130.957]\n",
      "After [0.0, 0.0, 0.008, 0.008, 0.059, 0.059, 0.065, 0.072, 0.074, 0.074, 0.082, 0.082, 0.083, 0.084, 0.095, 0.107, 0.129, 0.156, 0.172, 0.174, 0.175, 0.18, 0.186, 0.205, 0.219, 0.25, 0.279, 0.312, 0.328, 0.349, 0.358, 0.383, 0.393, 0.399, 0.405, 0.406, 0.409, 0.421, 0.426, 0.427, 0.427, 0.443, 0.458, 0.467, 0.469, 0.489, 0.491, 0.506, 0.512, 0.512, 0.521, 0.531, 0.537, 0.547, 0.556, 0.561, 0.566, 0.58, 0.59, 0.631, 0.633, 0.649, 0.659, 0.674, 0.69, 0.69, 0.697, 0.701, 0.705, 0.712, 0.723, 0.726, 0.731, 0.737, 0.747, 0.765, 0.765, 0.767, 0.809, 0.818, 0.836, 0.86, 0.865, 0.873, 0.878, 0.879, 0.884, 0.911, 0.927, 0.984, 0.987, 0.989, 0.998, 1.007, 1.016, 1.018, 1.028, 1.056, 1.069, 1.072, 1.076, 1.077, 1.1, 1.117, 1.129, 1.138, 1.144, 1.145, 1.147, 1.159, 1.166, 1.169, 1.172, 1.181, 1.201, 1.204, 1.215, 1.215, 1.224, 1.247, 1.247, 1.247, 1.247, 1.247, 1.247, 1.247, 1.247, 1.247, 1.25, 1.251, 1.271, 1.279, 1.285, 1.289, 1.296, 1.306, 1.314, 1.316, 1.323, 1.326, 1.347, 1.351, 1.354, 1.37, 1.386, 1.406, 1.407, 1.429, 1.442, 1.46, 1.497, 1.508, 1.53, 1.584, 1.584, 1.618, 1.635, 1.64, 1.642, 1.658, 1.688, 1.695, 1.697, 1.699, 1.706, 1.727, 1.736, 1.772, 1.808, 1.825, 1.829, 1.834, 1.866, 1.88, 1.903, 1.916, 1.919, 1.926, 1.931, 1.957, 1.999, 2.002, 2.007, 2.023, 2.044, 2.046, 2.081, 2.135, 2.141, 2.165, 2.251, 2.261, 2.278, 2.294, 2.301, 2.304, 2.396, 2.444, 2.448, 2.459, 2.479, 2.487, 2.543, 2.559, 2.559, 2.572, 2.58, 2.58, 2.65, 2.659, 2.776, 2.781, 2.781, 2.816, 2.852, 2.857, 2.868, 2.921, 2.948, 2.965, 2.976, 2.988, 2.993, 3.005, 3.046, 3.075, 3.075, 3.081, 3.087, 3.087, 3.093, 3.093, 3.1, 3.112, 3.124, 3.149, 3.156, 3.188, 3.227, 3.24, 3.247, 3.247, 3.26, 3.267, 3.288, 3.308, 3.372, 3.38, 3.387, 3.409, 3.484, 3.484, 3.492, 3.524, 3.555, 3.555, 3.563, 3.655, 3.751, 3.769, 3.778, 3.842, 3.89, 3.89, 3.989, 4.04, 4.05, 4.05, 4.082, 4.082, 4.135, 4.157, 4.168, 4.202, 4.259, 4.27, 4.282, 4.305, 4.317, 4.317, 4.365, 4.402, 4.464, 4.464, 4.464, 4.49, 4.516, 4.555, 4.595, 4.595, 4.595, 4.622, 4.649, 4.762, 4.791, 4.835, 4.85, 4.85, 4.926, 4.942, 4.989, 5.053, 5.086, 5.102, 5.169, 5.186, 5.186, 5.238, 5.291, 5.291, 5.327, 5.327, 5.4, 5.419, 5.438, 5.495, 5.533, 5.573, 5.573, 5.612, 5.633, 5.633, 5.653, 5.653, 5.673, 5.694, 5.714, 5.756, 5.778, 5.799, 5.82, 5.864, 5.864, 5.908, 5.953, 6.021, 6.044, 6.139, 6.163, 6.211, 6.211, 6.236, 6.236, 6.236, 6.286, 6.337, 6.362, 6.388, 6.521, 6.521, 6.548, 6.575, 6.631, 6.687, 6.716, 6.774, 6.833, 6.923, 6.923, 6.984, 7.047, 7.047, 7.047, 7.079, 7.079, 7.079, 7.111, 7.111, 7.176, 7.309, 7.378, 7.413, 7.413, 7.519, 7.555, 7.592, 7.666, 7.741, 7.741, 7.818, 7.818, 7.818, 7.977, 7.977, 7.977, 8.018, 8.059, 8.059, 8.1, 8.1, 8.185, 8.185, 8.185, 8.228, 8.228, 8.228, 8.359, 8.404, 8.449, 8.449, 8.541, 8.541, 8.541, 8.541, 8.587, 8.587, 8.635, 8.635, 8.635, 8.73, 8.73, 8.779, 8.829, 8.878, 8.929, 8.929, 8.98, 8.98, 9.084, 9.137, 9.19, 9.19, 9.299, 9.299, 9.41, 9.41, 9.41, 9.467, 9.701, 9.701, 9.761, 9.822, 9.884, 10.074, 10.074, 10.204, 10.204, 10.204, 10.271, 10.339, 10.339, 10.339, 10.407, 10.618, 10.618, 10.618, 10.838, 11.067, 11.067, 11.306, 11.388, 11.388, 11.388, 11.471, 11.641, 11.727, 11.727, 11.816, 11.905, 11.905, 12.088, 12.182, 12.182, 12.277, 12.277, 12.277, 12.277, 12.374, 12.472, 12.472, 12.572, 12.572, 12.673, 12.673, 12.673, 12.776, 12.881, 12.987, 12.987, 12.987, 12.987, 13.096, 13.096, 13.206, 13.318, 13.318, 13.431, 13.431, 13.547, 13.547, 13.785, 13.907, 13.907, 13.907, 13.907, 14.031, 14.031, 14.158, 14.158, 14.158, 14.417, 14.417, 14.551, 14.551, 14.551, 14.551, 14.551, 14.687, 14.687, 14.687, 14.687, 14.825, 14.967, 14.967, 14.967, 14.967, 14.967, 15.11, 15.11, 15.11, 15.11, 15.11, 15.11, 15.407, 15.407, 15.559, 15.559, 15.559, 15.559, 15.559, 15.559, 15.715, 15.715, 15.715, 15.874, 16.036, 16.036, 16.036, 16.201, 16.201, 16.201, 16.37, 16.37, 16.37, 16.37, 16.37, 16.542, 16.718, 16.718, 16.718, 16.718, 16.898, 16.898, 16.898, 16.898, 17.081, 17.081, 17.081, 17.081, 17.269, 17.269, 17.269, 17.269, 17.269, 17.461, 17.461, 17.461, 17.461, 17.461, 17.657, 17.657, 17.858, 17.858, 17.858, 17.858, 18.063, 18.063, 18.063, 18.063, 18.273, 18.273, 18.488, 18.708, 18.708, 18.934, 18.934, 18.934, 18.934, 18.934, 19.164, 19.164, 19.164, 19.401, 19.644, 19.644, 19.644, 19.644, 19.892, 19.892, 20.147, 20.409, 20.409, 20.409, 20.409, 20.677, 20.677, 20.677, 20.677, 20.953, 20.953, 21.236, 21.236, 21.236, 21.236, 21.527, 21.826, 21.826, 21.826, 21.826, 21.826, 21.826, 21.826, 22.134, 22.134, 22.134, 22.134, 22.45, 22.45, 23.11, 23.11, 23.11, 23.11, 23.455, 23.455, 23.455, 23.455, 23.81, 23.81, 23.81, 23.81, 23.81, 23.81, 23.81, 24.177, 24.177, 24.177, 24.177, 24.177, 24.177, 24.177, 24.554, 24.554, 24.554, 24.554, 24.944, 25.347, 25.347, 25.347, 25.762, 25.762, 25.762, 25.762, 26.191, 26.191, 26.635, 26.635, 26.635, 26.635, 26.635, 26.635, 26.635, 26.635, 26.635, 26.635, 26.635, 26.635, 26.635, 27.095, 27.095, 27.095, 27.095, 27.095, 27.57, 27.57, 27.57, 27.57, 27.57, 28.062, 28.062, 28.062, 28.062, 28.062, 28.572, 28.572, 29.651, 29.651, 29.651, 30.221, 30.221, 30.221, 30.221, 31.43, 31.43, 31.43, 31.43, 32.071, 32.071, 32.071, 32.739, 32.739, 33.436, 33.436, 34.163, 34.163, 34.163, 35.716, 38.329, 38.329, 40.294, 40.294, 40.294, 41.355, 43.652, 47.621, 54.189, 92.44, 130.957]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-69fb21ac0a4c>:144: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  self.val_MCR(F.softmax(y_hat),y)\n",
      "<ipython-input-5-69fb21ac0a4c>:145: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  self.val_CM_normalized(F.softmax(y_hat),y)\n",
      "/home/waris/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: 88694 nan values found in confusion matrix have been replaced with zeros.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "<ipython-input-5-69fb21ac0a4c>:146: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  self.val_CM_raw(F.softmax(y_hat),y)\n",
      "/home/waris/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: 243545 nan values found in confusion matrix have been replaced with zeros.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/waris/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: 69065 nan values found in confusion matrix have been replaced with zeros.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "::Val Loss = 7.0704 acc>0.5= 1, acc>=0.3= 1, Total=727 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6b4a2b92528451d89a38c625c42244d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "HBox(children=(HTML(value='Finding best initial lr'), FloatProgress(value=0.0), HTML(value='')))"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-69fb21ac0a4c>:124: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  self.train_CM_normalized(F.softmax(y_hat),y)\n",
      "/home/waris/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: 215919 nan values found in confusion matrix have been replaced with zeros.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "<ipython-input-5-69fb21ac0a4c>:125: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  self.train_CM_raw(F.softmax(y_hat),y)\n",
      "/home/waris/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: 107596 nan values found in confusion matrix have been replaced with zeros.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/waris/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: 125771 nan values found in confusion matrix have been replaced with zeros.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/waris/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: 287892 nan values found in confusion matrix have been replaced with zeros.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/waris/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: 242091 nan values found in confusion matrix have been replaced with zeros.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/waris/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: 327877 nan values found in confusion matrix have been replaced with zeros.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/waris/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: 362773 nan values found in confusion matrix have been replaced with zeros.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/waris/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: 133768 nan values found in confusion matrix have been replaced with zeros.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/waris/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: 280622 nan values found in confusion matrix have been replaced with zeros.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/waris/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: 294435 nan values found in confusion matrix have been replaced with zeros.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/waris/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: 324242 nan values found in confusion matrix have been replaced with zeros.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/waris/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: 267536 nan values found in confusion matrix have been replaced with zeros.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/waris/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: 252996 nan values found in confusion matrix have been replaced with zeros.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/waris/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: 255177 nan values found in confusion matrix have been replaced with zeros.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/waris/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: 290800 nan values found in confusion matrix have been replaced with zeros.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/waris/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: 112685 nan values found in confusion matrix have been replaced with zeros.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/waris/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: 76335 nan values found in confusion matrix have been replaced with zeros.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/waris/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: 175934 nan values found in confusion matrix have been replaced with zeros.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/waris/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: 234821 nan values found in confusion matrix have been replaced with zeros.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/waris/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: 262447 nan values found in confusion matrix have been replaced with zeros.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "::Val Loss = 7.0456 acc>0.5= 1, acc>=0.3= 1, Total=727 \n",
      "[0]E, Avg Training loss = 7.0367 acc>0.5= 0, acc>=0.3= 0, Total=727 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/waris/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: 117774 nan values found in confusion matrix have been replaced with zeros.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/waris/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: 15994 nan values found in confusion matrix have been replaced with zeros.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/waris/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: 2181 nan values found in confusion matrix have been replaced with zeros.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "::Val Loss = 7.041 acc>0.5= 1, acc>=0.3= 1, Total=727 \n",
      "[1]E, Avg Training loss = 7.0345 acc>0.5= 0, acc>=0.3= 0, Total=727 ::Val Loss = 6.945 acc>0.5= 1, acc>=0.3= 1, Total=727 \n",
      "[2]E, Avg Training loss = 7.0109 acc>0.5= 0, acc>=0.3= 0, Total=727 ::Val Loss = 6.6546 acc>0.5= 1, acc>=0.3= 1, Total=727 \n",
      "[3]E, Avg Training loss = 6.7892 acc>0.5= 0, acc>=0.3= 0, Total=727 ::Val Loss = 6.8614 acc>0.5= 1, acc>=0.3= 1, Total=727 \n",
      "[4]E, Avg Training loss = 6.5266 acc>0.5= 0, acc>=0.3= 0, Total=727 [5]E, Avg Training loss = 6.9219 acc>0.5= 0, acc>=0.3= 0, Total=727 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/waris/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: 4362 nan values found in confusion matrix have been replaced with zeros.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Restored states from the checkpoint file at /home/waris/Github/research/predict-future-alarms/project/lr_find_temp_model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested lr = 0.008317637711026709\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 432x288 with 1 Axes>"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def weightCondition(w,avg_w):\n",
    "    if w<avg_w:\n",
    "        return w\n",
    "    else:\n",
    "        return avg_w\n",
    "\n",
    "# setup data\n",
    "config_data = {\n",
    "'dir-path' : \"../.data/\",\n",
    "'batch-size' :512, # Batch Size \n",
    "'seq-len' :12, # Sequence length\n",
    "}\n",
    "\n",
    "dm = MyDataModule(config=config_data)\n",
    "ws = dm.get_weight_per_class().cuda()\n",
    "\n",
    "print(\"Before\",[round(w.item(),3) for w in ws])\n",
    "# avg_w = sum(ws)/len(ws)\n",
    "# ws = torch.tensor([weightCondition(w,avg_w) for w in ws]).cuda()\n",
    "print(\"After\",[round(w.item(),3) for w in ws])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "config_model = {\n",
    "    'lr' : 0.001,\n",
    "    'dropout' : 0.2,\n",
    "    'weight-decay': 3.1,\n",
    "    'em-size' :256, # embedding dimension \n",
    "    'nhid' : 128, # the dimension of the feedforward network model in nn.TransformerEncoder\n",
    "    'nlayers' :4, # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "    'nhead' : 2, # the number of heads in the multiheadattention models\n",
    "    'seq-len': config_data['seq-len'], # dont use wandb config \n",
    "    'vocab-size':len(dm.vocab.stoi), # the size of vocabulary /also called tokens\n",
    "    'weight_per_class':ws,\n",
    "    \"val-file\":\"val-out.txt\",\n",
    "    \"train-file\":'train-out.txt',\n",
    "    \"vocab\": dm.vocab\n",
    "}\n",
    "\n",
    "with open (config_model[\"val-file\"],'w') as f:\n",
    "    f.write(\">> Starting\")\n",
    "\n",
    "with open (config_model[\"train-file\"],'w') as f:\n",
    "    f.write(\">> Starting\")\n",
    "\n",
    "# setup model - note how we refer to sweep parameters with wandb.config\n",
    "model = TransformerModel(config=config_model)\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "        monitor='val_epoch_loss',\n",
    "        min_delta=0,\n",
    "        patience=600,\n",
    "        verbose=True,\n",
    "        mode='min'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "trainer = Trainer(auto_lr_find=0.0001, precision=16,gpus=-1, num_nodes=1,  max_epochs=100, check_val_every_n_epoch=1,deterministic=True,gradient_clip_val=0.5,enable_pl_optimizer=True,callbacks=[early_stop_callback],progress_bar_refresh_rate=0)\n",
    "\n",
    "# Run learning rate finder\n",
    "lr_finder = trainer.tuner.lr_find(model,dm)\n",
    "\n",
    "# Results can be found in\n",
    "lr_finder.results\n",
    "\n",
    "# Plot with\n",
    "fig = lr_finder.plot(suggest=True)\n",
    "fig.show()\n",
    "\n",
    "# Pick point based on plot, or get suggestion\n",
    "new_lr = lr_finder.suggestion()\n",
    "\n",
    "print(f\"Suggested lr = {new_lr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "   | Name                | Type                   | Params\n",
      "----------------------------------------------------------------\n",
      "0  | pos_encoder         | PositionalEncoding     | 0     \n",
      "1  | transformer_encoder | TransformerEncoder     | 1.3 M \n",
      "2  | encoder             | Embedding              | 186 K \n",
      "3  | decoder             | Linear                 | 186 K \n",
      "4  | val_CM_normalized   | ConfusionMatrix        | 0     \n",
      "5  | val_CM_raw          | ConfusionMatrix        | 0     \n",
      "6  | train_CM_normalized | ConfusionMatrix        | 0     \n",
      "7  | train_CM_raw        | ConfusionMatrix        | 0     \n",
      "8  | test_CM             | ConfusionMatrix        | 0     \n",
      "9  | val_MCR             | MyClassificationReport | 0     \n",
      "10 | test_MCR            | MyClassificationReport | 0     \n",
      "----------------------------------------------------------------\n",
      "1.7 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.7 M     Total params\n",
      "<ipython-input-5-69fb21ac0a4c>:144: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  self.val_MCR(F.softmax(y_hat),y)\n",
      "<ipython-input-5-69fb21ac0a4c>:145: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  self.val_CM_normalized(F.softmax(y_hat),y)\n",
      "/home/waris/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: 88694 nan values found in confusion matrix have been replaced with zeros.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "<ipython-input-5-69fb21ac0a4c>:146: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  self.val_CM_raw(F.softmax(y_hat),y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "::Val Loss = 7.0704 acc>0.5= 1, acc>=0.3= 1, Total=727 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/waris/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: 243545 nan values found in confusion matrix have been replaced with zeros.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/waris/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: 69065 nan values found in confusion matrix have been replaced with zeros.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "<ipython-input-5-69fb21ac0a4c>:124: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  self.train_CM_normalized(F.softmax(y_hat),y)\n",
      "/home/waris/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: 215919 nan values found in confusion matrix have been replaced with zeros.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "<ipython-input-5-69fb21ac0a4c>:125: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  self.train_CM_raw(F.softmax(y_hat),y)\n",
      "/home/waris/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: 107596 nan values found in confusion matrix have been replaced with zeros.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/waris/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: 125771 nan values found in confusion matrix have been replaced with zeros.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/waris/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: 287892 nan values found in confusion matrix have been replaced with zeros.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/waris/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: 242091 nan values found in confusion matrix have been replaced with zeros.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/waris/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: 327877 nan values found in confusion matrix have been replaced with zeros.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/waris/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: 362773 nan values found in confusion matrix have been replaced with zeros.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/waris/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: 133768 nan values found in confusion matrix have been replaced with zeros.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/waris/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: 280622 nan values found in confusion matrix have been replaced with zeros.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/waris/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: 294435 nan values found in confusion matrix have been replaced with zeros.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/waris/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: 324242 nan values found in confusion matrix have been replaced with zeros.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/waris/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: 267536 nan values found in confusion matrix have been replaced with zeros.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/waris/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: 252996 nan values found in confusion matrix have been replaced with zeros.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/waris/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: 255177 nan values found in confusion matrix have been replaced with zeros.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/waris/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: 290800 nan values found in confusion matrix have been replaced with zeros.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/waris/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: 112685 nan values found in confusion matrix have been replaced with zeros.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/waris/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: 76335 nan values found in confusion matrix have been replaced with zeros.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/waris/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: 175934 nan values found in confusion matrix have been replaced with zeros.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/waris/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: 234821 nan values found in confusion matrix have been replaced with zeros.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/waris/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: 262447 nan values found in confusion matrix have been replaced with zeros.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "::Val Loss = 6.834 acc>0.5= 1, acc>=0.3= 1, Total=727 \n",
      "[1]E, Avg Training loss = 6.9596 acc>0.5= 0, acc>=0.3= 0, Total=727 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/waris/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: 117774 nan values found in confusion matrix have been replaced with zeros.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/waris/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: 15994 nan values found in confusion matrix have been replaced with zeros.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/waris/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: 2181 nan values found in confusion matrix have been replaced with zeros.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "::Val Loss = 6.6126 acc>0.5= 1, acc>=0.3= 4, Total=727 \n",
      "[2]E, Avg Training loss = 6.7503 acc>0.5= 0, acc>=0.3= 0, Total=727 ::Val Loss = 6.1469 acc>0.5= 19, acc>=0.3= 57, Total=727 \n",
      "[3]E, Avg Training loss = 6.0964 acc>0.5= 6, acc>=0.3= 19, Total=727 ::Val Loss = 5.864 acc>0.5= 54, acc>=0.3= 130, Total=727 \n",
      "[4]E, Avg Training loss = 5.6902 acc>0.5= 40, acc>=0.3= 104, Total=727 ::Val Loss = 5.5047 acc>0.5= 74, acc>=0.3= 159, Total=727 \n",
      "[5]E, Avg Training loss = 5.3941 acc>0.5= 74, acc>=0.3= 175, Total=727 ::Val Loss = 5.2776 acc>0.5= 92, acc>=0.3= 188, Total=727 \n",
      "[6]E, Avg Training loss = 5.125 acc>0.5= 103, acc>=0.3= 221, Total=727 ::Val Loss = 4.95 acc>0.5= 111, acc>=0.3= 202, Total=727 \n",
      "[7]E, Avg Training loss = 4.9174 acc>0.5= 119, acc>=0.3= 260, Total=727 ::Val Loss = 4.7655 acc>0.5= 118, acc>=0.3= 227, Total=727 \n",
      "[8]E, Avg Training loss = 4.7453 acc>0.5= 146, acc>=0.3= 274, Total=727 ::Val Loss = 4.6367 acc>0.5= 125, acc>=0.3= 221, Total=727 \n",
      "[9]E, Avg Training loss = 4.5747 acc>0.5= 152, acc>=0.3= 287, Total=727 ::Val Loss = 4.5588 acc>0.5= 126, acc>=0.3= 238, Total=727 \n",
      "[10]E, Avg Training loss = 4.4462 acc>0.5= 160, acc>=0.3= 302, Total=727 ::Val Loss = 4.4778 acc>0.5= 125, acc>=0.3= 236, Total=727 \n",
      "[11]E, Avg Training loss = 4.3725 acc>0.5= 167, acc>=0.3= 308, Total=727 ::Val Loss = 4.4044 acc>0.5= 130, acc>=0.3= 250, Total=727 \n",
      "[12]E, Avg Training loss = 4.3036 acc>0.5= 172, acc>=0.3= 314, Total=727 ::Val Loss = 4.3671 acc>0.5= 126, acc>=0.3= 245, Total=727 \n",
      "[13]E, Avg Training loss = 4.2129 acc>0.5= 169, acc>=0.3= 319, Total=727 ::Val Loss = 4.2973 acc>0.5= 136, acc>=0.3= 255, Total=727 \n",
      "[14]E, Avg Training loss = 4.1683 acc>0.5= 177, acc>=0.3= 326, Total=727 ::Val Loss = 4.2682 acc>0.5= 135, acc>=0.3= 252, Total=727 \n",
      "[15]E, Avg Training loss = 4.1111 acc>0.5= 183, acc>=0.3= 321, Total=727 ::Val Loss = 4.2398 acc>0.5= 132, acc>=0.3= 258, Total=727 \n",
      "[16]E, Avg Training loss = 4.0811 acc>0.5= 178, acc>=0.3= 328, Total=727 ::Val Loss = 4.1729 acc>0.5= 137, acc>=0.3= 256, Total=727 \n",
      "[17]E, Avg Training loss = 4.024 acc>0.5= 186, acc>=0.3= 335, Total=727 ::Val Loss = 4.1673 acc>0.5= 136, acc>=0.3= 261, Total=727 \n",
      "[18]E, Avg Training loss = 3.9912 acc>0.5= 184, acc>=0.3= 337, Total=727 ::Val Loss = 4.1609 acc>0.5= 142, acc>=0.3= 260, Total=727 \n",
      "[19]E, Avg Training loss = 3.9753 acc>0.5= 176, acc>=0.3= 343, Total=727 ::Val Loss = 4.1465 acc>0.5= 147, acc>=0.3= 255, Total=727 \n",
      "[20]E, Avg Training loss = 3.9549 acc>0.5= 185, acc>=0.3= 339, Total=727 ::Val Loss = 4.1677 acc>0.5= 141, acc>=0.3= 254, Total=727 \n",
      "[21]E, Avg Training loss = 3.9608 acc>0.5= 179, acc>=0.3= 346, Total=727 ::Val Loss = 4.1379 acc>0.5= 144, acc>=0.3= 263, Total=727 \n",
      "[22]E, Avg Training loss = 3.9298 acc>0.5= 183, acc>=0.3= 341, Total=727 ::Val Loss = 4.159 acc>0.5= 139, acc>=0.3= 262, Total=727 \n",
      "[23]E, Avg Training loss = 3.9603 acc>0.5= 185, acc>=0.3= 341, Total=727 ::Val Loss = 4.1532 acc>0.5= 141, acc>=0.3= 258, Total=727 \n",
      "[24]E, Avg Training loss = 3.9364 acc>0.5= 188, acc>=0.3= 342, Total=727 ::Val Loss = 4.1732 acc>0.5= 143, acc>=0.3= 258, Total=727 \n",
      "[25]E, Avg Training loss = 3.9388 acc>0.5= 191, acc>=0.3= 350, Total=727 ::Val Loss = 4.1678 acc>0.5= 144, acc>=0.3= 264, Total=727 \n",
      "[26]E, Avg Training loss = 3.9678 acc>0.5= 191, acc>=0.3= 339, Total=727 ::Val Loss = 4.1902 acc>0.5= 135, acc>=0.3= 257, Total=727 \n",
      "[27]E, Avg Training loss = 3.9484 acc>0.5= 193, acc>=0.3= 346, Total=727 ::Val Loss = 4.2002 acc>0.5= 142, acc>=0.3= 260, Total=727 \n",
      "[28]E, Avg Training loss = 3.9681 acc>0.5= 190, acc>=0.3= 351, Total=727 ::Val Loss = 4.207 acc>0.5= 144, acc>=0.3= 261, Total=727 \n",
      "[29]E, Avg Training loss = 4.0016 acc>0.5= 192, acc>=0.3= 339, Total=727 ::Val Loss = 4.2437 acc>0.5= 141, acc>=0.3= 256, Total=727 \n",
      "[30]E, Avg Training loss = 3.9978 acc>0.5= 184, acc>=0.3= 343, Total=727 ::Val Loss = 4.2538 acc>0.5= 138, acc>=0.3= 256, Total=727 \n",
      "[31]E, Avg Training loss = 4.0443 acc>0.5= 194, acc>=0.3= 329, Total=727 ::Val Loss = 4.2558 acc>0.5= 140, acc>=0.3= 256, Total=727 \n",
      "[32]E, Avg Training loss = 4.0358 acc>0.5= 197, acc>=0.3= 334, Total=727 ::Val Loss = 4.3217 acc>0.5= 144, acc>=0.3= 253, Total=727 \n",
      "[33]E, Avg Training loss = 4.0736 acc>0.5= 183, acc>=0.3= 331, Total=727 Epoch    33: reducing learning rate of group 0 to 5.0000e-04.\n",
      "::Val Loss = 4.2621 acc>0.5= 148, acc>=0.3= 256, Total=727 \n",
      "[34]E, Avg Training loss = 4.0753 acc>0.5= 188, acc>=0.3= 334, Total=727 ::Val Loss = 4.2373 acc>0.5= 148, acc>=0.3= 255, Total=727 \n",
      "[35]E, Avg Training loss = 4.0253 acc>0.5= 202, acc>=0.3= 329, Total=727 ::Val Loss = 4.239 acc>0.5= 144, acc>=0.3= 260, Total=727 \n",
      "[36]E, Avg Training loss = 4.0217 acc>0.5= 192, acc>=0.3= 331, Total=727 ::Val Loss = 4.231 acc>0.5= 146, acc>=0.3= 257, Total=727 \n",
      "[37]E, Avg Training loss = 4.0229 acc>0.5= 197, acc>=0.3= 330, Total=727 ::Val Loss = 4.2175 acc>0.5= 140, acc>=0.3= 253, Total=727 \n",
      "[38]E, Avg Training loss = 4.0092 acc>0.5= 193, acc>=0.3= 333, Total=727 ::Val Loss = 4.2157 acc>0.5= 145, acc>=0.3= 257, Total=727 \n",
      "[39]E, Avg Training loss = 3.9946 acc>0.5= 194, acc>=0.3= 329, Total=727 ::Val Loss = 4.2288 acc>0.5= 142, acc>=0.3= 259, Total=727 \n",
      "[40]E, Avg Training loss = 4.0007 acc>0.5= 192, acc>=0.3= 330, Total=727 ::Val Loss = 4.2385 acc>0.5= 144, acc>=0.3= 256, Total=727 \n",
      "[41]E, Avg Training loss = 4.0149 acc>0.5= 194, acc>=0.3= 331, Total=727 ::Val Loss = 4.2443 acc>0.5= 146, acc>=0.3= 256, Total=727 \n",
      "[42]E, Avg Training loss = 4.0132 acc>0.5= 191, acc>=0.3= 323, Total=727 ::Val Loss = 4.2401 acc>0.5= 146, acc>=0.3= 256, Total=727 \n",
      "[43]E, Avg Training loss = 4.0158 acc>0.5= 195, acc>=0.3= 328, Total=727 ::Val Loss = 4.255 acc>0.5= 142, acc>=0.3= 257, Total=727 \n",
      "[44]E, Avg Training loss = 4.0403 acc>0.5= 191, acc>=0.3= 330, Total=727 Epoch    44: reducing learning rate of group 0 to 2.5000e-04.\n",
      "::Val Loss = 4.2345 acc>0.5= 138, acc>=0.3= 256, Total=727 \n",
      "[45]E, Avg Training loss = 4.0197 acc>0.5= 189, acc>=0.3= 326, Total=727 ::Val Loss = 4.2232 acc>0.5= 140, acc>=0.3= 259, Total=727 \n",
      "[46]E, Avg Training loss = 3.9961 acc>0.5= 199, acc>=0.3= 323, Total=727 ::Val Loss = 4.2188 acc>0.5= 144, acc>=0.3= 259, Total=727 \n",
      "[47]E, Avg Training loss = 3.9949 acc>0.5= 196, acc>=0.3= 327, Total=727 ::Val Loss = 4.2272 acc>0.5= 147, acc>=0.3= 257, Total=727 \n",
      "[48]E, Avg Training loss = 3.9959 acc>0.5= 199, acc>=0.3= 326, Total=727 ::Val Loss = 4.2262 acc>0.5= 144, acc>=0.3= 258, Total=727 \n",
      "[49]E, Avg Training loss = 3.9939 acc>0.5= 197, acc>=0.3= 329, Total=727 ::Val Loss = 4.2185 acc>0.5= 145, acc>=0.3= 259, Total=727 \n",
      "[50]E, Avg Training loss = 4.0005 acc>0.5= 193, acc>=0.3= 324, Total=727 ::Val Loss = 4.2275 acc>0.5= 142, acc>=0.3= 255, Total=727 \n",
      "[51]E, Avg Training loss = 4.0003 acc>0.5= 194, acc>=0.3= 322, Total=727 ::Val Loss = 4.2383 acc>0.5= 146, acc>=0.3= 253, Total=727 \n",
      "[52]E, Avg Training loss = 4.0033 acc>0.5= 196, acc>=0.3= 330, Total=727 ::Val Loss = 4.2427 acc>0.5= 141, acc>=0.3= 254, Total=727 \n",
      "[53]E, Avg Training loss = 4.0106 acc>0.5= 196, acc>=0.3= 325, Total=727 ::Val Loss = 4.2345 acc>0.5= 143, acc>=0.3= 257, Total=727 \n",
      "[54]E, Avg Training loss = 4.0178 acc>0.5= 194, acc>=0.3= 328, Total=727 ::Val Loss = 4.2522 acc>0.5= 145, acc>=0.3= 256, Total=727 \n",
      "[55]E, Avg Training loss = 4.0189 acc>0.5= 191, acc>=0.3= 321, Total=727 Epoch    55: reducing learning rate of group 0 to 1.2500e-04.\n",
      "::Val Loss = 4.238 acc>0.5= 143, acc>=0.3= 254, Total=727 \n",
      "[56]E, Avg Training loss = 4.0201 acc>0.5= 196, acc>=0.3= 323, Total=727 ::Val Loss = 4.2299 acc>0.5= 142, acc>=0.3= 256, Total=727 \n",
      "[57]E, Avg Training loss = 4.0044 acc>0.5= 194, acc>=0.3= 327, Total=727 ::Val Loss = 4.2272 acc>0.5= 141, acc>=0.3= 259, Total=727 \n",
      "[58]E, Avg Training loss = 4.001 acc>0.5= 192, acc>=0.3= 329, Total=727 ::Val Loss = 4.225 acc>0.5= 145, acc>=0.3= 255, Total=727 \n",
      "[59]E, Avg Training loss = 3.9957 acc>0.5= 196, acc>=0.3= 320, Total=727 ::Val Loss = 4.2202 acc>0.5= 145, acc>=0.3= 254, Total=727 \n",
      "[60]E, Avg Training loss = 3.9886 acc>0.5= 199, acc>=0.3= 319, Total=727 ::Val Loss = 4.2182 acc>0.5= 145, acc>=0.3= 253, Total=727 \n",
      "[61]E, Avg Training loss = 3.9853 acc>0.5= 197, acc>=0.3= 326, Total=727 ::Val Loss = 4.2168 acc>0.5= 144, acc>=0.3= 257, Total=727 \n",
      "[62]E, Avg Training loss = 3.9868 acc>0.5= 192, acc>=0.3= 327, Total=727 ::Val Loss = 4.2159 acc>0.5= 144, acc>=0.3= 253, Total=727 \n",
      "[63]E, Avg Training loss = 3.9832 acc>0.5= 195, acc>=0.3= 325, Total=727 ::Val Loss = 4.2144 acc>0.5= 144, acc>=0.3= 251, Total=727 \n",
      "[64]E, Avg Training loss = 3.9791 acc>0.5= 196, acc>=0.3= 325, Total=727 ::Val Loss = 4.2141 acc>0.5= 146, acc>=0.3= 256, Total=727 \n",
      "[65]E, Avg Training loss = 3.979 acc>0.5= 197, acc>=0.3= 325, Total=727 ::Val Loss = 4.2128 acc>0.5= 147, acc>=0.3= 254, Total=727 \n",
      "[66]E, Avg Training loss = 3.9829 acc>0.5= 195, acc>=0.3= 328, Total=727 Epoch    66: reducing learning rate of group 0 to 6.2500e-05.\n",
      "::Val Loss = 4.2116 acc>0.5= 146, acc>=0.3= 253, Total=727 \n",
      "[67]E, Avg Training loss = 3.9758 acc>0.5= 197, acc>=0.3= 330, Total=727 ::Val Loss = 4.2088 acc>0.5= 144, acc>=0.3= 253, Total=727 \n",
      "[68]E, Avg Training loss = 3.9709 acc>0.5= 197, acc>=0.3= 327, Total=727 ::Val Loss = 4.2069 acc>0.5= 146, acc>=0.3= 253, Total=727 \n",
      "[69]E, Avg Training loss = 3.969 acc>0.5= 197, acc>=0.3= 329, Total=727 ::Val Loss = 4.2053 acc>0.5= 146, acc>=0.3= 253, Total=727 \n",
      "[70]E, Avg Training loss = 3.9656 acc>0.5= 199, acc>=0.3= 325, Total=727 ::Val Loss = 4.2042 acc>0.5= 145, acc>=0.3= 252, Total=727 \n",
      "[71]E, Avg Training loss = 3.9648 acc>0.5= 197, acc>=0.3= 327, Total=727 ::Val Loss = 4.2025 acc>0.5= 146, acc>=0.3= 252, Total=727 \n",
      "[72]E, Avg Training loss = 3.9615 acc>0.5= 198, acc>=0.3= 328, Total=727 ::Val Loss = 4.2012 acc>0.5= 146, acc>=0.3= 251, Total=727 \n",
      "[73]E, Avg Training loss = 3.9596 acc>0.5= 194, acc>=0.3= 320, Total=727 ::Val Loss = 4.1997 acc>0.5= 146, acc>=0.3= 252, Total=727 \n",
      "[74]E, Avg Training loss = 3.9581 acc>0.5= 200, acc>=0.3= 326, Total=727 ::Val Loss = 4.1984 acc>0.5= 146, acc>=0.3= 250, Total=727 \n",
      "[75]E, Avg Training loss = 3.9575 acc>0.5= 197, acc>=0.3= 332, Total=727 ::Val Loss = 4.1974 acc>0.5= 146, acc>=0.3= 252, Total=727 \n",
      "[76]E, Avg Training loss = 3.954 acc>0.5= 201, acc>=0.3= 328, Total=727 ::Val Loss = 4.1962 acc>0.5= 145, acc>=0.3= 252, Total=727 \n",
      "[77]E, Avg Training loss = 3.9541 acc>0.5= 197, acc>=0.3= 331, Total=727 Epoch    77: reducing learning rate of group 0 to 3.1250e-05.\n",
      "::Val Loss = 4.1956 acc>0.5= 145, acc>=0.3= 252, Total=727 \n",
      "[78]E, Avg Training loss = 3.952 acc>0.5= 197, acc>=0.3= 325, Total=727 ::Val Loss = 4.195 acc>0.5= 145, acc>=0.3= 252, Total=727 \n",
      "[79]E, Avg Training loss = 3.9506 acc>0.5= 197, acc>=0.3= 330, Total=727 ::Val Loss = 4.1945 acc>0.5= 145, acc>=0.3= 252, Total=727 \n",
      "[80]E, Avg Training loss = 3.9502 acc>0.5= 199, acc>=0.3= 325, Total=727 ::Val Loss = 4.1939 acc>0.5= 145, acc>=0.3= 252, Total=727 \n",
      "[81]E, Avg Training loss = 3.9489 acc>0.5= 199, acc>=0.3= 330, Total=727 ::Val Loss = 4.1934 acc>0.5= 145, acc>=0.3= 252, Total=727 \n",
      "[82]E, Avg Training loss = 3.9491 acc>0.5= 198, acc>=0.3= 328, Total=727 ::Val Loss = 4.193 acc>0.5= 145, acc>=0.3= 252, Total=727 \n",
      "[83]E, Avg Training loss = 3.947 acc>0.5= 203, acc>=0.3= 332, Total=727 ::Val Loss = 4.1925 acc>0.5= 146, acc>=0.3= 252, Total=727 \n",
      "[84]E, Avg Training loss = 3.9478 acc>0.5= 197, acc>=0.3= 330, Total=727 ::Val Loss = 4.192 acc>0.5= 146, acc>=0.3= 252, Total=727 \n",
      "[85]E, Avg Training loss = 3.9468 acc>0.5= 196, acc>=0.3= 334, Total=727 ::Val Loss = 4.1916 acc>0.5= 146, acc>=0.3= 252, Total=727 \n",
      "[86]E, Avg Training loss = 3.9472 acc>0.5= 197, acc>=0.3= 334, Total=727 ::Val Loss = 4.1913 acc>0.5= 146, acc>=0.3= 252, Total=727 \n",
      "[87]E, Avg Training loss = 3.9463 acc>0.5= 194, acc>=0.3= 334, Total=727 ::Val Loss = 4.1909 acc>0.5= 146, acc>=0.3= 252, Total=727 \n",
      "[88]E, Avg Training loss = 3.9448 acc>0.5= 196, acc>=0.3= 332, Total=727 Epoch    88: reducing learning rate of group 0 to 1.5625e-05.\n",
      "::Val Loss = 4.1906 acc>0.5= 146, acc>=0.3= 252, Total=727 \n",
      "[89]E, Avg Training loss = 3.9434 acc>0.5= 200, acc>=0.3= 330, Total=727 ::Val Loss = 4.1905 acc>0.5= 146, acc>=0.3= 252, Total=727 \n",
      "[90]E, Avg Training loss = 3.9433 acc>0.5= 199, acc>=0.3= 331, Total=727 ::Val Loss = 4.1903 acc>0.5= 146, acc>=0.3= 252, Total=727 \n",
      "[91]E, Avg Training loss = 3.9432 acc>0.5= 197, acc>=0.3= 330, Total=727 ::Val Loss = 4.19 acc>0.5= 146, acc>=0.3= 252, Total=727 \n",
      "[92]E, Avg Training loss = 3.9428 acc>0.5= 197, acc>=0.3= 325, Total=727 ::Val Loss = 4.1898 acc>0.5= 146, acc>=0.3= 252, Total=727 \n",
      "[93]E, Avg Training loss = 3.9425 acc>0.5= 192, acc>=0.3= 328, Total=727 ::Val Loss = 4.1896 acc>0.5= 146, acc>=0.3= 252, Total=727 \n",
      "[94]E, Avg Training loss = 3.9435 acc>0.5= 197, acc>=0.3= 328, Total=727 ::Val Loss = 4.1894 acc>0.5= 146, acc>=0.3= 252, Total=727 \n",
      "[95]E, Avg Training loss = 3.9426 acc>0.5= 199, acc>=0.3= 330, Total=727 ::Val Loss = 4.1892 acc>0.5= 146, acc>=0.3= 252, Total=727 \n",
      "[96]E, Avg Training loss = 3.9413 acc>0.5= 195, acc>=0.3= 329, Total=727 ::Val Loss = 4.189 acc>0.5= 146, acc>=0.3= 252, Total=727 \n",
      "[97]E, Avg Training loss = 3.9408 acc>0.5= 197, acc>=0.3= 332, Total=727 ::Val Loss = 4.1888 acc>0.5= 146, acc>=0.3= 252, Total=727 \n",
      "[98]E, Avg Training loss = 3.9413 acc>0.5= 202, acc>=0.3= 328, Total=727 ::Val Loss = 4.1887 acc>0.5= 146, acc>=0.3= 252, Total=727 \n",
      "[99]E, Avg Training loss = 3.9421 acc>0.5= 195, acc>=0.3= 330, Total=727 Epoch    99: reducing learning rate of group 0 to 7.8125e-06.\n"
     ]
    },
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.hparams.lr = new_lr/100 #7.5e-12 # can devide by 10\n",
    "\n",
    "trainer.fit(model,dm) # Fit model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.test(datamodule=dm) # testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traninng RNNs\n",
    "Finding the learning rate for the RNN model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48716lines [00:00, 81830.80lines/s]\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Using native 16bit precision.\n",
      "\n",
      "   | Name                | Type                   | Params\n",
      "----------------------------------------------------------------\n",
      "0  | val_CM_normalized   | ConfusionMatrix        | 0     \n",
      "1  | val_CM_raw          | ConfusionMatrix        | 0     \n",
      "2  | train_CM_normalized | ConfusionMatrix        | 0     \n",
      "3  | train_CM_raw        | ConfusionMatrix        | 0     \n",
      "4  | test_CM             | ConfusionMatrix        | 0     \n",
      "5  | val_MCR             | MyClassificationReport | 0     \n",
      "6  | test_MCR            | MyClassificationReport | 0     \n",
      "7  | embedding           | Embedding              | 186 K \n",
      "8  | gru                 | GRU                    | 4.3 M \n",
      "9  | fc3                 | Linear                 | 372 K \n",
      "10 | softmax             | LogSoftmax             | 0     \n",
      "----------------------------------------------------------------\n",
      "4.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.9 M     Total params\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before [0.0, 0.0, 0.008, 0.008, 0.059, 0.059, 0.065, 0.072, 0.074, 0.074, 0.082, 0.082, 0.083, 0.084, 0.095, 0.107, 0.129, 0.156, 0.172, 0.174, 0.175, 0.18, 0.186, 0.205, 0.219, 0.25, 0.279, 0.312, 0.328, 0.349, 0.358, 0.383, 0.393, 0.399, 0.405, 0.406, 0.409, 0.421, 0.426, 0.427, 0.427, 0.443, 0.458, 0.467, 0.469, 0.489, 0.491, 0.506, 0.512, 0.512, 0.521, 0.531, 0.537, 0.547, 0.556, 0.561, 0.566, 0.58, 0.59, 0.631, 0.633, 0.649, 0.659, 0.674, 0.69, 0.69, 0.697, 0.701, 0.705, 0.712, 0.723, 0.726, 0.731, 0.737, 0.747, 0.765, 0.765, 0.767, 0.809, 0.818, 0.836, 0.86, 0.865, 0.873, 0.878, 0.879, 0.884, 0.911, 0.927, 0.984, 0.987, 0.989, 0.998, 1.007, 1.016, 1.018, 1.028, 1.056, 1.069, 1.072, 1.076, 1.077, 1.1, 1.117, 1.129, 1.138, 1.144, 1.145, 1.147, 1.159, 1.166, 1.169, 1.172, 1.181, 1.201, 1.204, 1.215, 1.215, 1.224, 1.247, 1.247, 1.247, 1.247, 1.247, 1.247, 1.247, 1.247, 1.247, 1.25, 1.251, 1.271, 1.279, 1.285, 1.289, 1.296, 1.306, 1.314, 1.316, 1.323, 1.326, 1.347, 1.351, 1.354, 1.37, 1.386, 1.406, 1.407, 1.429, 1.442, 1.46, 1.497, 1.508, 1.53, 1.584, 1.584, 1.618, 1.635, 1.64, 1.642, 1.658, 1.688, 1.695, 1.697, 1.699, 1.706, 1.727, 1.736, 1.772, 1.808, 1.825, 1.829, 1.834, 1.866, 1.88, 1.903, 1.916, 1.919, 1.926, 1.931, 1.957, 1.999, 2.002, 2.007, 2.023, 2.044, 2.046, 2.081, 2.135, 2.141, 2.165, 2.251, 2.261, 2.278, 2.294, 2.301, 2.304, 2.396, 2.444, 2.448, 2.459, 2.479, 2.487, 2.543, 2.559, 2.559, 2.572, 2.58, 2.58, 2.65, 2.659, 2.776, 2.781, 2.781, 2.816, 2.852, 2.857, 2.868, 2.921, 2.948, 2.965, 2.976, 2.988, 2.993, 3.005, 3.046, 3.075, 3.075, 3.081, 3.087, 3.087, 3.093, 3.093, 3.1, 3.112, 3.124, 3.149, 3.156, 3.188, 3.227, 3.24, 3.247, 3.247, 3.26, 3.267, 3.288, 3.308, 3.372, 3.38, 3.387, 3.409, 3.484, 3.484, 3.492, 3.524, 3.555, 3.555, 3.563, 3.655, 3.751, 3.769, 3.778, 3.842, 3.89, 3.89, 3.989, 4.04, 4.05, 4.05, 4.082, 4.082, 4.135, 4.157, 4.168, 4.202, 4.259, 4.27, 4.282, 4.305, 4.317, 4.317, 4.365, 4.402, 4.464, 4.464, 4.464, 4.49, 4.516, 4.555, 4.595, 4.595, 4.595, 4.622, 4.649, 4.762, 4.791, 4.835, 4.85, 4.85, 4.926, 4.942, 4.989, 5.053, 5.086, 5.102, 5.169, 5.186, 5.186, 5.238, 5.291, 5.291, 5.327, 5.327, 5.4, 5.419, 5.438, 5.495, 5.533, 5.573, 5.573, 5.612, 5.633, 5.633, 5.653, 5.653, 5.673, 5.694, 5.714, 5.756, 5.778, 5.799, 5.82, 5.864, 5.864, 5.908, 5.953, 6.021, 6.044, 6.139, 6.163, 6.211, 6.211, 6.236, 6.236, 6.236, 6.286, 6.337, 6.362, 6.388, 6.521, 6.521, 6.548, 6.575, 6.631, 6.687, 6.716, 6.774, 6.833, 6.923, 6.923, 6.984, 7.047, 7.047, 7.047, 7.079, 7.079, 7.079, 7.111, 7.111, 7.176, 7.309, 7.378, 7.413, 7.413, 7.519, 7.555, 7.592, 7.666, 7.741, 7.741, 7.818, 7.818, 7.818, 7.977, 7.977, 7.977, 8.018, 8.059, 8.059, 8.1, 8.1, 8.185, 8.185, 8.185, 8.228, 8.228, 8.228, 8.359, 8.404, 8.449, 8.449, 8.541, 8.541, 8.541, 8.541, 8.587, 8.587, 8.635, 8.635, 8.635, 8.73, 8.73, 8.779, 8.829, 8.878, 8.929, 8.929, 8.98, 8.98, 9.084, 9.137, 9.19, 9.19, 9.299, 9.299, 9.41, 9.41, 9.41, 9.467, 9.701, 9.701, 9.761, 9.822, 9.884, 10.074, 10.074, 10.204, 10.204, 10.204, 10.271, 10.339, 10.339, 10.339, 10.407, 10.618, 10.618, 10.618, 10.838, 11.067, 11.067, 11.306, 11.388, 11.388, 11.388, 11.471, 11.641, 11.727, 11.727, 11.816, 11.905, 11.905, 12.088, 12.182, 12.182, 12.277, 12.277, 12.277, 12.277, 12.374, 12.472, 12.472, 12.572, 12.572, 12.673, 12.673, 12.673, 12.776, 12.881, 12.987, 12.987, 12.987, 12.987, 13.096, 13.096, 13.206, 13.318, 13.318, 13.431, 13.431, 13.547, 13.547, 13.785, 13.907, 13.907, 13.907, 13.907, 14.031, 14.031, 14.158, 14.158, 14.158, 14.417, 14.417, 14.551, 14.551, 14.551, 14.551, 14.551, 14.687, 14.687, 14.687, 14.687, 14.825, 14.967, 14.967, 14.967, 14.967, 14.967, 15.11, 15.11, 15.11, 15.11, 15.11, 15.11, 15.407, 15.407, 15.559, 15.559, 15.559, 15.559, 15.559, 15.559, 15.715, 15.715, 15.715, 15.874, 16.036, 16.036, 16.036, 16.201, 16.201, 16.201, 16.37, 16.37, 16.37, 16.37, 16.37, 16.542, 16.718, 16.718, 16.718, 16.718, 16.898, 16.898, 16.898, 16.898, 17.081, 17.081, 17.081, 17.081, 17.269, 17.269, 17.269, 17.269, 17.269, 17.461, 17.461, 17.461, 17.461, 17.461, 17.657, 17.657, 17.858, 17.858, 17.858, 17.858, 18.063, 18.063, 18.063, 18.063, 18.273, 18.273, 18.488, 18.708, 18.708, 18.934, 18.934, 18.934, 18.934, 18.934, 19.164, 19.164, 19.164, 19.401, 19.644, 19.644, 19.644, 19.644, 19.892, 19.892, 20.147, 20.409, 20.409, 20.409, 20.409, 20.677, 20.677, 20.677, 20.677, 20.953, 20.953, 21.236, 21.236, 21.236, 21.236, 21.527, 21.826, 21.826, 21.826, 21.826, 21.826, 21.826, 21.826, 22.134, 22.134, 22.134, 22.134, 22.45, 22.45, 23.11, 23.11, 23.11, 23.11, 23.455, 23.455, 23.455, 23.455, 23.81, 23.81, 23.81, 23.81, 23.81, 23.81, 23.81, 24.177, 24.177, 24.177, 24.177, 24.177, 24.177, 24.177, 24.554, 24.554, 24.554, 24.554, 24.944, 25.347, 25.347, 25.347, 25.762, 25.762, 25.762, 25.762, 26.191, 26.191, 26.635, 26.635, 26.635, 26.635, 26.635, 26.635, 26.635, 26.635, 26.635, 26.635, 26.635, 26.635, 26.635, 27.095, 27.095, 27.095, 27.095, 27.095, 27.57, 27.57, 27.57, 27.57, 27.57, 28.062, 28.062, 28.062, 28.062, 28.062, 28.572, 28.572, 29.651, 29.651, 29.651, 30.221, 30.221, 30.221, 30.221, 31.43, 31.43, 31.43, 31.43, 32.071, 32.071, 32.071, 32.739, 32.739, 33.436, 33.436, 34.163, 34.163, 34.163, 35.716, 38.329, 38.329, 40.294, 40.294, 40.294, 41.355, 43.652, 47.621, 54.189, 92.44, 130.957]\n",
      "After [0.0, 0.0, 0.008, 0.008, 0.059, 0.059, 0.065, 0.072, 0.074, 0.074, 0.082, 0.082, 0.083, 0.084, 0.095, 0.107, 0.129, 0.156, 0.172, 0.174, 0.175, 0.18, 0.186, 0.205, 0.219, 0.25, 0.279, 0.312, 0.328, 0.349, 0.358, 0.383, 0.393, 0.399, 0.405, 0.406, 0.409, 0.421, 0.426, 0.427, 0.427, 0.443, 0.458, 0.467, 0.469, 0.489, 0.491, 0.506, 0.512, 0.512, 0.521, 0.531, 0.537, 0.547, 0.556, 0.561, 0.566, 0.58, 0.59, 0.631, 0.633, 0.649, 0.659, 0.674, 0.69, 0.69, 0.697, 0.701, 0.705, 0.712, 0.723, 0.726, 0.731, 0.737, 0.747, 0.765, 0.765, 0.767, 0.809, 0.818, 0.836, 0.86, 0.865, 0.873, 0.878, 0.879, 0.884, 0.911, 0.927, 0.984, 0.987, 0.989, 0.998, 1.007, 1.016, 1.018, 1.028, 1.056, 1.069, 1.072, 1.076, 1.077, 1.1, 1.117, 1.129, 1.138, 1.144, 1.145, 1.147, 1.159, 1.166, 1.169, 1.172, 1.181, 1.201, 1.204, 1.215, 1.215, 1.224, 1.247, 1.247, 1.247, 1.247, 1.247, 1.247, 1.247, 1.247, 1.247, 1.25, 1.251, 1.271, 1.279, 1.285, 1.289, 1.296, 1.306, 1.314, 1.316, 1.323, 1.326, 1.347, 1.351, 1.354, 1.37, 1.386, 1.406, 1.407, 1.429, 1.442, 1.46, 1.497, 1.508, 1.53, 1.584, 1.584, 1.618, 1.635, 1.64, 1.642, 1.658, 1.688, 1.695, 1.697, 1.699, 1.706, 1.727, 1.736, 1.772, 1.808, 1.825, 1.829, 1.834, 1.866, 1.88, 1.903, 1.916, 1.919, 1.926, 1.931, 1.957, 1.999, 2.002, 2.007, 2.023, 2.044, 2.046, 2.081, 2.135, 2.141, 2.165, 2.251, 2.261, 2.278, 2.294, 2.301, 2.304, 2.396, 2.444, 2.448, 2.459, 2.479, 2.487, 2.543, 2.559, 2.559, 2.572, 2.58, 2.58, 2.65, 2.659, 2.776, 2.781, 2.781, 2.816, 2.852, 2.857, 2.868, 2.921, 2.948, 2.965, 2.976, 2.988, 2.993, 3.005, 3.046, 3.075, 3.075, 3.081, 3.087, 3.087, 3.093, 3.093, 3.1, 3.112, 3.124, 3.149, 3.156, 3.188, 3.227, 3.24, 3.247, 3.247, 3.26, 3.267, 3.288, 3.308, 3.372, 3.38, 3.387, 3.409, 3.484, 3.484, 3.492, 3.524, 3.555, 3.555, 3.563, 3.655, 3.751, 3.769, 3.778, 3.842, 3.89, 3.89, 3.989, 4.04, 4.05, 4.05, 4.082, 4.082, 4.135, 4.157, 4.168, 4.202, 4.259, 4.27, 4.282, 4.305, 4.317, 4.317, 4.365, 4.402, 4.464, 4.464, 4.464, 4.49, 4.516, 4.555, 4.595, 4.595, 4.595, 4.622, 4.649, 4.762, 4.791, 4.835, 4.85, 4.85, 4.926, 4.942, 4.989, 5.053, 5.086, 5.102, 5.169, 5.186, 5.186, 5.238, 5.291, 5.291, 5.327, 5.327, 5.4, 5.419, 5.438, 5.495, 5.533, 5.573, 5.573, 5.612, 5.633, 5.633, 5.653, 5.653, 5.673, 5.694, 5.714, 5.756, 5.778, 5.799, 5.82, 5.864, 5.864, 5.908, 5.953, 6.021, 6.044, 6.139, 6.163, 6.211, 6.211, 6.236, 6.236, 6.236, 6.286, 6.337, 6.362, 6.388, 6.521, 6.521, 6.548, 6.575, 6.631, 6.687, 6.716, 6.774, 6.833, 6.923, 6.923, 6.984, 7.047, 7.047, 7.047, 7.079, 7.079, 7.079, 7.111, 7.111, 7.176, 7.309, 7.378, 7.413, 7.413, 7.519, 7.555, 7.592, 7.666, 7.741, 7.741, 7.818, 7.818, 7.818, 7.977, 7.977, 7.977, 8.018, 8.059, 8.059, 8.1, 8.1, 8.185, 8.185, 8.185, 8.228, 8.228, 8.228, 8.359, 8.404, 8.449, 8.449, 8.541, 8.541, 8.541, 8.541, 8.587, 8.587, 8.635, 8.635, 8.635, 8.73, 8.73, 8.779, 8.829, 8.878, 8.929, 8.929, 8.98, 8.98, 9.084, 9.137, 9.19, 9.19, 9.299, 9.299, 9.41, 9.41, 9.41, 9.467, 9.701, 9.701, 9.761, 9.822, 9.884, 10.074, 10.074, 10.204, 10.204, 10.204, 10.271, 10.339, 10.339, 10.339, 10.407, 10.618, 10.618, 10.618, 10.838, 11.067, 11.067, 11.306, 11.388, 11.388, 11.388, 11.471, 11.641, 11.727, 11.727, 11.816, 11.905, 11.905, 12.088, 12.182, 12.182, 12.277, 12.277, 12.277, 12.277, 12.374, 12.472, 12.472, 12.572, 12.572, 12.673, 12.673, 12.673, 12.776, 12.881, 12.987, 12.987, 12.987, 12.987, 13.096, 13.096, 13.206, 13.318, 13.318, 13.431, 13.431, 13.547, 13.547, 13.785, 13.907, 13.907, 13.907, 13.907, 14.031, 14.031, 14.158, 14.158, 14.158, 14.417, 14.417, 14.551, 14.551, 14.551, 14.551, 14.551, 14.687, 14.687, 14.687, 14.687, 14.825, 14.967, 14.967, 14.967, 14.967, 14.967, 15.11, 15.11, 15.11, 15.11, 15.11, 15.11, 15.407, 15.407, 15.559, 15.559, 15.559, 15.559, 15.559, 15.559, 15.715, 15.715, 15.715, 15.874, 16.036, 16.036, 16.036, 16.201, 16.201, 16.201, 16.37, 16.37, 16.37, 16.37, 16.37, 16.542, 16.718, 16.718, 16.718, 16.718, 16.898, 16.898, 16.898, 16.898, 17.081, 17.081, 17.081, 17.081, 17.269, 17.269, 17.269, 17.269, 17.269, 17.461, 17.461, 17.461, 17.461, 17.461, 17.657, 17.657, 17.858, 17.858, 17.858, 17.858, 18.063, 18.063, 18.063, 18.063, 18.273, 18.273, 18.488, 18.708, 18.708, 18.934, 18.934, 18.934, 18.934, 18.934, 19.164, 19.164, 19.164, 19.401, 19.644, 19.644, 19.644, 19.644, 19.892, 19.892, 20.147, 20.409, 20.409, 20.409, 20.409, 20.677, 20.677, 20.677, 20.677, 20.953, 20.953, 21.236, 21.236, 21.236, 21.236, 21.527, 21.826, 21.826, 21.826, 21.826, 21.826, 21.826, 21.826, 22.134, 22.134, 22.134, 22.134, 22.45, 22.45, 23.11, 23.11, 23.11, 23.11, 23.455, 23.455, 23.455, 23.455, 23.81, 23.81, 23.81, 23.81, 23.81, 23.81, 23.81, 24.177, 24.177, 24.177, 24.177, 24.177, 24.177, 24.177, 24.554, 24.554, 24.554, 24.554, 24.944, 25.347, 25.347, 25.347, 25.762, 25.762, 25.762, 25.762, 26.191, 26.191, 26.635, 26.635, 26.635, 26.635, 26.635, 26.635, 26.635, 26.635, 26.635, 26.635, 26.635, 26.635, 26.635, 27.095, 27.095, 27.095, 27.095, 27.095, 27.57, 27.57, 27.57, 27.57, 27.57, 28.062, 28.062, 28.062, 28.062, 28.062, 28.572, 28.572, 29.651, 29.651, 29.651, 30.221, 30.221, 30.221, 30.221, 31.43, 31.43, 31.43, 31.43, 32.071, 32.071, 32.071, 32.739, 32.739, 33.436, 33.436, 34.163, 34.163, 34.163, 35.716, 38.329, 38.329, 40.294, 40.294, 40.294, 41.355, 43.652, 47.621, 54.189, 92.44, 130.957]\n",
      "::Val Loss = 6.582 acc>0.5= 0, acc>=0.3= 0, Total=727 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f42a4212ad649418ff0ceaeab699e74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "HBox(children=(HTML(value='Finding best initial lr'), FloatProgress(value=0.0), HTML(value='')))"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "::Val Loss = 6.5826 acc>0.5= 0, acc>=0.3= 0, Total=727 \n",
      "[0]E, Avg Training loss = 6.5838 acc>0.5= 0, acc>=0.3= 0, Total=727 ::Val Loss = 6.5711 acc>0.5= 0, acc>=0.3= 0, Total=727 \n",
      "[1]E, Avg Training loss = 6.5805 acc>0.5= 0, acc>=0.3= 0, Total=727 ::Val Loss = 6.2869 acc>0.5= 2, acc>=0.3= 3, Total=727 \n",
      "[2]E, Avg Training loss = 6.5025 acc>0.5= 1, acc>=0.3= 1, Total=727 ::Val Loss = 4.6605 acc>0.5= 3, acc>=0.3= 3, Total=727 \n",
      "[3]E, Avg Training loss = 5.0474 acc>0.5= 2, acc>=0.3= 2, Total=727 ::Val Loss = 17.8006 acc>0.5= 1, acc>=0.3= 1, Total=727 \n",
      "[4]E, Avg Training loss = 6.4483 acc>0.5= 1, acc>=0.3= 1, Total=727 [5]E, Avg Training loss = 14.3116 acc>0.5= 0, acc>=0.3= 1, Total=727 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/waris/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: 4362 nan values found in confusion matrix have been replaced with zeros.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Restored states from the checkpoint file at /home/waris/Github/research/predict-future-alarms/project/lr_find_temp_model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested lr = 0.001584893192461114\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 432x288 with 1 Axes>"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# setup data\n",
    "config_data = {\n",
    "'dir-path' : \"../.data/\",\n",
    "'batch-size' :512, # Batch Size \n",
    "'seq-len' :128, # Sequence length change to 6\n",
    "}\n",
    "\n",
    "dm = MyDataModule(config=config_data)\n",
    "ws = dm.get_weight_per_class().cuda()\n",
    "\n",
    "print(\"Before\",[round(w.item(),3) for w in ws])\n",
    "# avg_w = sum(ws)/len(ws)\n",
    "# ws = torch.tensor([weightCondition(w,avg_w) for w in ws]).cuda()\n",
    "print(\"After\",[round(w.item(),3) for w in ws])\n",
    "\n",
    "\n",
    "config_model = {\n",
    "    'lr' : 0.001,\n",
    "    'dropout' : 0.05,\n",
    "    'weight-decay': 3.1, #3.1,\n",
    "    'em-size' :256, # embedding dimension \n",
    "    'nhid' : 512, # the dimension of the feedforward network model in nn.TransformerEncoder\n",
    "    'nlayers' :3, # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "    'seq-len': config_data['seq-len'], # dont use wandb config \n",
    "    'vocab-size':len(dm.vocab.stoi), # the size of vocabulary /also called tokens\n",
    "    'weight_per_class':ws,\n",
    "    \"val-file\":\"val-out-rnn.txt\",\n",
    "    \"train-file\":'train-out-rnn.txt',\n",
    "    \"vocab\": dm.vocab,\n",
    "    \"batch-size\":config_data['batch-size']\n",
    "}\n",
    "\n",
    "with open (config_model[\"val-file\"],'w') as f:\n",
    "    f.write(\">> Starting\")\n",
    "\n",
    "with open (config_model[\"train-file\"],'w') as f:\n",
    "    f.write(\">> Starting\")\n",
    "\n",
    "\n",
    "\n",
    "model = AlarmGRU(config=config_model)\n",
    "model.initialize_hidden()\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "        monitor='val_epoch_loss',\n",
    "        min_delta=0,\n",
    "        patience=100,\n",
    "        verbose=True,\n",
    "        mode='min'\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(auto_lr_find=0.0001, precision=16,gpus=-1, num_nodes=1,  max_epochs=100, check_val_every_n_epoch=1,deterministic=True,gradient_clip_val=0.5,enable_pl_optimizer=True,callbacks=[early_stop_callback],progress_bar_refresh_rate=0)\n",
    "\n",
    "# Run learning rate finder\n",
    "lr_finder = trainer.tuner.lr_find(model,dm)\n",
    "\n",
    "# Results can be found in\n",
    "lr_finder.results\n",
    "\n",
    "# Plot with\n",
    "fig = lr_finder.plot(suggest=True)\n",
    "fig.show()\n",
    "\n",
    "# Pick point based on plot, or get suggestion\n",
    "new_lr = lr_finder.suggestion()\n",
    "\n",
    "print(f\"Suggested lr = {new_lr}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "   | Name                | Type                   | Params\n",
      "----------------------------------------------------------------\n",
      "0  | val_CM_normalized   | ConfusionMatrix        | 0     \n",
      "1  | val_CM_raw          | ConfusionMatrix        | 0     \n",
      "2  | train_CM_normalized | ConfusionMatrix        | 0     \n",
      "3  | train_CM_raw        | ConfusionMatrix        | 0     \n",
      "4  | test_CM             | ConfusionMatrix        | 0     \n",
      "5  | val_MCR             | MyClassificationReport | 0     \n",
      "6  | test_MCR            | MyClassificationReport | 0     \n",
      "7  | embedding           | Embedding              | 186 K \n",
      "8  | gru                 | GRU                    | 4.3 M \n",
      "9  | fc3                 | Linear                 | 372 K \n",
      "10 | softmax             | LogSoftmax             | 0     \n",
      "----------------------------------------------------------------\n",
      "4.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.9 M     Total params\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "::Val Loss = 6.5813 acc>0.5= 0, acc>=0.3= 0, Total=727 \n",
      "::Val Loss = 4.361 acc>0.5= 2, acc>=0.3= 2, Total=727 \n",
      "[1]E, Avg Training loss = 5.3283 acc>0.5= 1, acc>=0.3= 1, Total=727 ::Val Loss = 3.972 acc>0.5= 3, acc>=0.3= 6, Total=727 \n",
      "[2]E, Avg Training loss = 4.0123 acc>0.5= 3, acc>=0.3= 3, Total=727 ::Val Loss = 3.8363 acc>0.5= 4, acc>=0.3= 5, Total=727 \n",
      "[3]E, Avg Training loss = 3.6721 acc>0.5= 4, acc>=0.3= 7, Total=727 ::Val Loss = 3.6503 acc>0.5= 6, acc>=0.3= 9, Total=727 \n",
      "[4]E, Avg Training loss = 3.4991 acc>0.5= 6, acc>=0.3= 7, Total=727 ::Val Loss = 3.5004 acc>0.5= 9, acc>=0.3= 10, Total=727 \n",
      "[5]E, Avg Training loss = 3.2491 acc>0.5= 8, acc>=0.3= 12, Total=727 ::Val Loss = 3.3612 acc>0.5= 6, acc>=0.3= 12, Total=727 \n",
      "[6]E, Avg Training loss = 3.2074 acc>0.5= 10, acc>=0.3= 13, Total=727 ::Val Loss = 3.3259 acc>0.5= 9, acc>=0.3= 12, Total=727 \n",
      "[7]E, Avg Training loss = 3.1134 acc>0.5= 10, acc>=0.3= 13, Total=727 ::Val Loss = 3.2585 acc>0.5= 11, acc>=0.3= 15, Total=727 \n",
      "[8]E, Avg Training loss = 3.1124 acc>0.5= 11, acc>=0.3= 14, Total=727 ::Val Loss = 3.1862 acc>0.5= 11, acc>=0.3= 19, Total=727 \n",
      "[9]E, Avg Training loss = 2.975 acc>0.5= 14, acc>=0.3= 16, Total=727 ::Val Loss = 3.1272 acc>0.5= 8, acc>=0.3= 15, Total=727 \n",
      "[10]E, Avg Training loss = 2.9917 acc>0.5= 13, acc>=0.3= 21, Total=727 ::Val Loss = 3.1231 acc>0.5= 12, acc>=0.3= 19, Total=727 \n",
      "[11]E, Avg Training loss = 2.9443 acc>0.5= 10, acc>=0.3= 15, Total=727 ::Val Loss = 3.1145 acc>0.5= 12, acc>=0.3= 20, Total=727 \n",
      "[12]E, Avg Training loss = 2.9166 acc>0.5= 15, acc>=0.3= 28, Total=727 ::Val Loss = 2.969 acc>0.5= 14, acc>=0.3= 26, Total=727 \n",
      "[13]E, Avg Training loss = 2.7993 acc>0.5= 17, acc>=0.3= 24, Total=727 ::Val Loss = 2.9982 acc>0.5= 10, acc>=0.3= 20, Total=727 \n",
      "[14]E, Avg Training loss = 2.7478 acc>0.5= 25, acc>=0.3= 36, Total=727 ::Val Loss = 2.9709 acc>0.5= 16, acc>=0.3= 29, Total=727 \n",
      "[15]E, Avg Training loss = 2.7194 acc>0.5= 22, acc>=0.3= 32, Total=727 ::Val Loss = 2.9425 acc>0.5= 12, acc>=0.3= 27, Total=727 \n",
      "[16]E, Avg Training loss = 2.6695 acc>0.5= 22, acc>=0.3= 39, Total=727 ::Val Loss = 2.8979 acc>0.5= 20, acc>=0.3= 32, Total=727 \n",
      "[17]E, Avg Training loss = 2.661 acc>0.5= 25, acc>=0.3= 42, Total=727 ::Val Loss = 2.9369 acc>0.5= 14, acc>=0.3= 34, Total=727 \n",
      "[18]E, Avg Training loss = 2.5508 acc>0.5= 28, acc>=0.3= 50, Total=727 ::Val Loss = 2.8429 acc>0.5= 16, acc>=0.3= 28, Total=727 \n",
      "[19]E, Avg Training loss = 2.6127 acc>0.5= 33, acc>=0.3= 54, Total=727 ::Val Loss = 2.8746 acc>0.5= 20, acc>=0.3= 39, Total=727 \n",
      "[20]E, Avg Training loss = 2.5407 acc>0.5= 27, acc>=0.3= 51, Total=727 ::Val Loss = 2.8448 acc>0.5= 13, acc>=0.3= 30, Total=727 \n",
      "[21]E, Avg Training loss = 2.5737 acc>0.5= 35, acc>=0.3= 63, Total=727 ::Val Loss = 2.8355 acc>0.5= 22, acc>=0.3= 46, Total=727 \n",
      "[22]E, Avg Training loss = 2.5474 acc>0.5= 34, acc>=0.3= 63, Total=727 ::Val Loss = 2.813 acc>0.5= 20, acc>=0.3= 30, Total=727 \n",
      "[23]E, Avg Training loss = 2.5151 acc>0.5= 35, acc>=0.3= 59, Total=727 ::Val Loss = 2.8216 acc>0.5= 22, acc>=0.3= 41, Total=727 \n",
      "[24]E, Avg Training loss = 2.507 acc>0.5= 33, acc>=0.3= 60, Total=727 ::Val Loss = 2.7954 acc>0.5= 18, acc>=0.3= 36, Total=727 \n",
      "[25]E, Avg Training loss = 2.4971 acc>0.5= 39, acc>=0.3= 61, Total=727 ::Val Loss = 2.8112 acc>0.5= 22, acc>=0.3= 39, Total=727 \n",
      "[26]E, Avg Training loss = 2.4797 acc>0.5= 38, acc>=0.3= 63, Total=727 ::Val Loss = 2.8029 acc>0.5= 19, acc>=0.3= 38, Total=727 \n",
      "[27]E, Avg Training loss = 2.4488 acc>0.5= 38, acc>=0.3= 77, Total=727 ::Val Loss = 2.8042 acc>0.5= 26, acc>=0.3= 47, Total=727 \n",
      "[28]E, Avg Training loss = 2.4762 acc>0.5= 38, acc>=0.3= 68, Total=727 ::Val Loss = 2.7649 acc>0.5= 22, acc>=0.3= 39, Total=727 \n",
      "[29]E, Avg Training loss = 2.4182 acc>0.5= 48, acc>=0.3= 78, Total=727 ::Val Loss = 2.7723 acc>0.5= 24, acc>=0.3= 48, Total=727 \n",
      "[30]E, Avg Training loss = 2.4452 acc>0.5= 40, acc>=0.3= 81, Total=727 ::Val Loss = 2.8039 acc>0.5= 25, acc>=0.3= 44, Total=727 \n",
      "[31]E, Avg Training loss = 2.3894 acc>0.5= 43, acc>=0.3= 75, Total=727 ::Val Loss = 2.7702 acc>0.5= 19, acc>=0.3= 45, Total=727 \n",
      "[32]E, Avg Training loss = 2.4642 acc>0.5= 47, acc>=0.3= 84, Total=727 ::Val Loss = 2.8156 acc>0.5= 30, acc>=0.3= 55, Total=727 \n",
      "[33]E, Avg Training loss = 2.3954 acc>0.5= 42, acc>=0.3= 80, Total=727 ::Val Loss = 2.7644 acc>0.5= 19, acc>=0.3= 40, Total=727 \n",
      "[34]E, Avg Training loss = 2.4523 acc>0.5= 47, acc>=0.3= 84, Total=727 ::Val Loss = 2.7447 acc>0.5= 24, acc>=0.3= 45, Total=727 \n",
      "[35]E, Avg Training loss = 2.4225 acc>0.5= 48, acc>=0.3= 88, Total=727 ::Val Loss = 2.7592 acc>0.5= 34, acc>=0.3= 58, Total=727 \n",
      "[36]E, Avg Training loss = 2.3692 \n",
      "acc>0.5= 40, acc>=0.3= 78, Total=727 ::Val Loss = 2.7616 acc>0.5= 25, acc>=0.3= 47, Total=727 \n",
      "[37]E, Avg Training loss = 2.4464 acc>0.5= 53, acc>=0.3= 103, Total=727 ::Val Loss = 2.816 acc>0.5= 31, acc>=0.3= 61, Total=727 \n",
      "[38]E, Avg Training loss = 2.3924 acc>0.5= 44, acc>=0.3= 86, Total=727 ::Val Loss = 2.7109 acc>0.5= 25, acc>=0.3= 47, Total=727 \n",
      "[39]E, Avg Training loss = 2.463 acc>0.5= 49, acc>=0.3= 99, Total=727 ::Val Loss = 2.7253 acc>0.5= 35, acc>=0.3= 61, Total=727 \n",
      "[40]E, Avg Training loss = 2.3928 acc>0.5= 40, acc>=0.3= 79, Total=727 ::Val Loss = 2.7056 acc>0.5= 26, acc>=0.3= 57, Total=727 \n",
      "[41]E, Avg Training loss = 2.4325 acc>0.5= 43, acc>=0.3= 96, Total=727 ::Val Loss = 2.7115 acc>0.5= 28, acc>=0.3= 56, Total=727 \n",
      "[42]E, Avg Training loss = 2.331 acc>0.5= 48, acc>=0.3= 100, Total=727 ::Val Loss = 2.7131 acc>0.5= 30, acc>=0.3= 50, Total=727 \n",
      "[43]E, Avg Training loss = 2.3429 acc>0.5= 51, acc>=0.3= 96, Total=727 ::Val Loss = 2.6584 acc>0.5= 36, acc>=0.3= 61, Total=727 \n",
      "[44]E, Avg Training loss = 2.3494 acc>0.5= 48, acc>=0.3= 98, Total=727 ::Val Loss = 2.6778 acc>0.5= 27, acc>=0.3= 57, Total=727 \n",
      "[45]E, Avg Training loss = 2.3523 acc>0.5= 51, acc>=0.3= 99, Total=727 ::Val Loss = 2.6299 acc>0.5= 30, acc>=0.3= 60, Total=727 \n",
      "[46]E, Avg Training loss = 2.3089 acc>0.5= 50, acc>=0.3= 98, Total=727 ::Val Loss = 2.7249 acc>0.5= 28, acc>=0.3= 57, Total=727 \n",
      "[47]E, Avg Training loss = 2.3064 acc>0.5= 57, acc>=0.3= 106, Total=727 ::Val Loss = 2.7067 acc>0.5= 23, acc>=0.3= 46, Total=727 \n",
      "[48]E, Avg Training loss = 2.3338 acc>0.5= 50, acc>=0.3= 101, Total=727 ::Val Loss = 2.6421 acc>0.5= 33, acc>=0.3= 57, Total=727 \n",
      "[49]E, Avg Training loss = 2.3278 acc>0.5= 50, acc>=0.3= 93, Total=727 ::Val Loss = 2.6953 acc>0.5= 32, acc>=0.3= 65, Total=727 \n",
      "[50]E, Avg Training loss = 2.2862 acc>0.5= 49, acc>=0.3= 102, Total=727 ::Val Loss = 2.6819 acc>0.5= 30, acc>=0.3= 54, Total=727 \n",
      "[51]E, Avg Training loss = 2.3301 acc>0.5= 63, acc>=0.3= 109, Total=727 ::Val Loss = 2.778 acc>0.5= 27, acc>=0.3= 55, Total=727 \n",
      "[52]E, Avg Training loss = 2.3521 acc>0.5= 51, acc>=0.3= 101, Total=727 ::Val Loss = 2.7469 acc>0.5= 26, acc>=0.3= 59, Total=727 \n",
      "[53]E, Avg Training loss = 2.4448 acc>0.5= 49, acc>=0.3= 93, Total=727 ::Val Loss = 2.7986 acc>0.5= 28, acc>=0.3= 61, Total=727 \n",
      "[54]E, Avg Training loss = 2.3784 acc>0.5= 60, acc>=0.3= 98, Total=727 ::Val Loss = 2.6075 acc>0.5= 33, acc>=0.3= 63, Total=727 \n",
      "[55]E, Avg Training loss = 2.4102 acc>0.5= 56, acc>=0.3= 106, Total=727 ::Val Loss = 2.6739 acc>0.5= 29, acc>=0.3= 62, Total=727 \n",
      "[56]E, Avg Training loss = 2.2669 acc>0.5= 51, acc>=0.3= 108, Total=727 ::Val Loss = 2.6869 acc>0.5= 30, acc>=0.3= 63, Total=727 \n",
      "[57]E, Avg Training loss = 2.3159 acc>0.5= 58, acc>=0.3= 112, Total=727 ::Val Loss = 2.7519 acc>0.5= 45, acc>=0.3= 78, Total=727 \n",
      "[58]E, Avg Training loss = 2.3538 acc>0.5= 47, acc>=0.3= 100, Total=727 ::Val Loss = 2.6785 acc>0.5= 23, acc>=0.3= 52, Total=727 \n",
      "[59]E, Avg Training loss = 2.4571 acc>0.5= 69, acc>=0.3= 133, Total=727 ::Val Loss = 2.644 acc>0.5= 36, acc>=0.3= 75, Total=727 \n",
      "[60]E, Avg Training loss = 2.2893 acc>0.5= 50, acc>=0.3= 103, Total=727 ::Val Loss = 2.6491 acc>0.5= 35, acc>=0.3= 70, Total=727 \n",
      "[61]E, Avg Training loss = 2.2816 acc>0.5= 58, acc>=0.3= 111, Total=727 ::Val Loss = 2.6472 acc>0.5= 21, acc>=0.3= 49, Total=727 \n",
      "[62]E, Avg Training loss = 2.3092 acc>0.5= 64, acc>=0.3= 130, Total=727 ::Val Loss = 2.6783 acc>0.5= 40, acc>=0.3= 77, Total=727 \n",
      "[63]E, Avg Training loss = 2.3053 acc>0.5= 47, acc>=0.3= 92, Total=727 ::Val Loss = 2.6089 acc>0.5= 32, acc>=0.3= 60, Total=727 \n",
      "[64]E, Avg Training loss = 2.2552 acc>0.5= 61, acc>=0.3= 113, Total=727 ::Val Loss = 2.6613 acc>0.5= 32, acc>=0.3= 67, Total=727 \n",
      "[65]E, Avg Training loss = 2.2944 acc>0.5= 62, acc>=0.3= 125, Total=727 ::Val Loss = 2.655 acc>0.5= 40, acc>=0.3= 82, Total=727 \n",
      "[66]E, Avg Training loss = 2.2645 acc>0.5= 54, acc>=0.3= 115, Total=727 Epoch    66: reducing learning rate of group 0 to 5.0000e-04.\n",
      "::Val Loss = 2.5318 acc>0.5= 41, acc>=0.3= 78, Total=727 \n",
      "[67]E, Avg Training loss = 2.2551 acc>0.5= 74, acc>=0.3= 129, Total=727 ::Val Loss = 2.5026 acc>0.5= 43, acc>=0.3= 87, Total=727 \n",
      "[68]E, Avg Training loss = 2.1461 acc>0.5= 67, acc>=0.3= 137, Total=727 ::Val Loss = 2.503 acc>0.5= 39, acc>=0.3= 80, Total=727 \n",
      "[69]E, Avg Training loss = 2.1572 acc>0.5= 79, acc>=0.3= 133, Total=727 ::Val Loss = 2.4879 acc>0.5= 43, acc>=0.3= 91, Total=727 \n",
      "[70]E, Avg Training loss = 2.1377 acc>0.5= 60, acc>=0.3= 137, Total=727 ::Val Loss = 2.5147 acc>0.5= 40, acc>=0.3= 83, Total=727 \n",
      "[71]E, Avg Training loss = 2.1737 acc>0.5= 82, acc>=0.3= 155, Total=727 ::Val Loss = 2.4845 acc>0.5= 43, acc>=0.3= 96, Total=727 \n",
      "[72]E, Avg Training loss = 2.1142 acc>0.5= 67, acc>=0.3= 137, Total=727 ::Val Loss = 2.4781 acc>0.5= 38, acc>=0.3= 78, Total=727 \n",
      "[73]E, Avg Training loss = 2.122 acc>0.5= 75, acc>=0.3= 144, Total=727 ::Val Loss = 2.4675 acc>0.5= 45, acc>=0.3= 94, Total=727 \n",
      "[74]E, Avg Training loss = 2.1106 acc>0.5= 68, acc>=0.3= 148, Total=727 ::Val Loss = 2.4745 acc>0.5= 33, acc>=0.3= 80, Total=727 \n",
      "[75]E, Avg Training loss = 2.1202 acc>0.5= 75, acc>=0.3= 147, Total=727 ::Val Loss = 2.4556 acc>0.5= 51, acc>=0.3= 100, Total=727 \n",
      "[76]E, Avg Training loss = 2.0962 acc>0.5= 72, acc>=0.3= 158, Total=727 ::Val Loss = 2.4784 acc>0.5= 37, acc>=0.3= 77, Total=727 \n",
      "[77]E, Avg Training loss = 2.1 acc>0.5= 69, acc>=0.3= 142, Total=727 ::Val Loss = 2.4621 acc>0.5= 48, acc>=0.3= 98, Total=727 \n",
      "[78]E, Avg Training loss = 2.094 acc>0.5= 69, acc>=0.3= 150, Total=727 ::Val Loss = 2.4739 acc>0.5= 37, acc>=0.3= 77, Total=727 \n",
      "[79]E, Avg Training loss = 2.1089 acc>0.5= 71, acc>=0.3= 146, Total=727 ::Val Loss = 2.4615 acc>0.5= 52, acc>=0.3= 103, Total=727 \n",
      "[80]E, Avg Training loss = 2.0779 acc>0.5= 74, acc>=0.3= 148, Total=727 ::Val Loss = 2.4692 acc>0.5= 39, acc>=0.3= 83, Total=727 \n",
      "[81]E, Avg Training loss = 2.1038 acc>0.5= 79, acc>=0.3= 158, Total=727 ::Val Loss = 2.4588 acc>0.5= 40, acc>=0.3= 93, Total=727 \n",
      "[82]E, Avg Training loss = 2.0977 acc>0.5= 73, acc>=0.3= 162, Total=727 ::Val Loss = 2.4731 acc>0.5= 40, acc>=0.3= 83, Total=727 \n",
      "[83]E, Avg Training loss = 2.0994 acc>0.5= 72, acc>=0.3= 157, Total=727 ::Val Loss = 2.4656 acc>0.5= 59, acc>=0.3= 111, Total=727 \n",
      "[84]E, Avg Training loss = 2.0912 acc>0.5= 72, acc>=0.3= 146, Total=727 ::Val Loss = 2.4834 acc>0.5= 32, acc>=0.3= 73, Total=727 \n",
      "[85]E, Avg Training loss = 2.1172 acc>0.5= 86, acc>=0.3= 169, Total=727 ::Val Loss = 2.4959 acc>0.5= 47, acc>=0.3= 100, Total=727 \n",
      "[86]E, Avg Training loss = 2.0905 acc>0.5= 69, acc>=0.3= 141, Total=727 ::Val Loss = 2.4624 acc>0.5= 43, acc>=0.3= 88, Total=727 \n",
      "[87]E, Avg Training loss = 2.1311 acc>0.5= 79, acc>=0.3= 145, Total=727 Epoch    87: reducing learning rate of group 0 to 2.5000e-04.\n",
      "::Val Loss = 2.4122 acc>0.5= 45, acc>=0.3= 100, Total=727 \n",
      "[88]E, Avg Training loss = 2.0612 acc>0.5= 72, acc>=0.3= 157, Total=727 ::Val Loss = 2.4044 acc>0.5= 47, acc>=0.3= 106, Total=727 \n",
      "[89]E, Avg Training loss = 2.0345 acc>0.5= 84, acc>=0.3= 176, Total=727 ::Val Loss = 2.401 acc>0.5= 50, acc>=0.3= 105, Total=727 \n",
      "[90]E, Avg Training loss = 2.0233 acc>0.5= 80, acc>=0.3= 168, Total=727 ::Val Loss = 2.3942 acc>0.5= 47, acc>=0.3= 99, Total=727 \n",
      "[91]E, Avg Training loss = 2.0204 acc>0.5= 88, acc>=0.3= 178, Total=727 ::Val Loss = 2.3878 acc>0.5= 53, acc>=0.3= 112, Total=727 \n",
      "[92]E, Avg Training loss = 2.0112 acc>0.5= 80, acc>=0.3= 169, Total=727 ::Val Loss = 2.3894 acc>0.5= 46, acc>=0.3= 108, Total=727 \n",
      "[93]E, Avg Training loss = 2.0137 acc>0.5= 85, acc>=0.3= 182, Total=727 ::Val Loss = 2.3809 acc>0.5= 58, acc>=0.3= 110, Total=727 \n",
      "[94]E, Avg Training loss = 2.0001 acc>0.5= 84, acc>=0.3= 176, Total=727 ::Val Loss = 2.3844 acc>0.5= 46, acc>=0.3= 104, Total=727 \n",
      "[95]E, Avg Training loss = 2.0088 acc>0.5= 88, acc>=0.3= 188, Total=727 ::Val Loss = 2.3759 acc>0.5= 56, acc>=0.3= 115, Total=727 \n",
      "[96]E, Avg Training loss = 1.9964 acc>0.5= 87, acc>=0.3= 183, Total=727 ::Val Loss = 2.3813 acc>0.5= 50, acc>=0.3= 103, Total=727 \n",
      "[97]E, Avg Training loss = 1.9979 acc>0.5= 88, acc>=0.3= 184, Total=727 ::Val Loss = 2.375 acc>0.5= 52, acc>=0.3= 110, Total=727 \n",
      "[98]E, Avg Training loss = 1.9934 acc>0.5= 85, acc>=0.3= 183, Total=727 ::Val Loss = 2.3869 acc>0.5= 45, acc>=0.3= 104, Total=727 \n",
      "[99]E, Avg Training loss = 1.9946 acc>0.5= 85, acc>=0.3= 186, Total=727 "
     ]
    },
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.hparams.lr = new_lr/100 #7.5e-12 # can devide by 10\n",
    "trainer.fit(model,dm) # Fit model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.test(datamodule=dm) # testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "As we can see from the above outputs, in 100 epochs the Transformers models predict roughly more than 135 alarms sources with more than 50% accuracy while RNN model only able to predict 51 alrarm sources with more than 50% accuracy. Thus, the Transformers performs relative better as compared to RNNs on next alarm prediction task. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8076afad8c2f739e22f417bad77704dbad7b0389c4d6903b1ae4a1b7479f7ed3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('dl': conda)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}