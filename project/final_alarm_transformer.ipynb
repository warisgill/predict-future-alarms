{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for logging \n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from comet_ml import Experiment\n",
    "from pytorch_lightning.loggers import CometLogger\n",
    "from pytorch_lightning.loggers import TestTubeLogger\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import wandb\n",
    "\n",
    "# For metrics\n",
    "from pytorch_lightning import metrics\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import io\n",
    "import torchtext\n",
    "from torchtext.utils import download_from_url, extract_archive\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.trainer.trainer import Trainer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping # The EarlyStopping callback can be used to monitor a validation metric and stop the training when no improvement is observed.\n",
    "\"\"\"\n",
    "    To enable it:\n",
    "\n",
    "    Import EarlyStopping callback.\n",
    "\n",
    "    Log the metric you want to monitor using log() method.\n",
    "\n",
    "    Init the callback, and set monitor to the logged metric of your choice.\n",
    "\n",
    "    Pass the EarlyStopping callback to the Trainer callbacks flag.\n",
    "\"\"\"\n",
    "\n",
    "from pytorch_lightning import seed_everything\n",
    "# seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.metrics import Metric\n",
    "from pytorch_lightning.metrics.utils import _input_format_classification\n",
    "from sklearn.metrics import classification_report\n",
    "class MyClassificationReport(Metric):\n",
    "    def __init__(self,threshold: float = 0.5,compute_on_step: bool = True,dist_sync_on_step: bool = False):\n",
    "        super().__init__(\n",
    "            compute_on_step=compute_on_step,\n",
    "            dist_sync_on_step=dist_sync_on_step,\n",
    "        )\n",
    "\n",
    "        self.threshold = threshold\n",
    "        self.add_state(\"preds\", default=[], dist_reduce_fx=None)\n",
    "        self.add_state(\"target\", default=[], dist_reduce_fx=None)\n",
    "\n",
    "        # rank_zero_warn(\n",
    "        #     'Metric `MyClassificationReport` will save all targets and predictions in buffer.'\n",
    "        #     ' For large datasets this may lead to large memory footprint.'\n",
    "        # )\n",
    "\n",
    "    def update(self, preds: torch.Tensor, target: torch.Tensor):\n",
    "        preds = preds.cpu()\n",
    "        target = target.cpu()\n",
    "        y_hat, y = preds.max(1).indices, target\n",
    "        assert y_hat.shape == y.shape\n",
    "        self.preds.append(y_hat)\n",
    "        self.target.append(y)\n",
    "\n",
    "    def compute(self):\n",
    "        preds = torch.cat(self.preds, dim=0)\n",
    "        target = torch.cat(self.target, dim=0)\n",
    "        return classification_report(y_true=target,y_pred=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AlarmDataset(Dataset):\n",
    "    def __init__(self,data,seq_len,batch_size):\n",
    "        self.length = len(data)//seq_len # how much data i have         \n",
    "        self.data = data\n",
    "        self.seq_len = seq_len\n",
    "        self.batch_size = batch_size\n",
    "       \n",
    "    def __getitem__(self, index: int):\n",
    "        x = self.data[index*self.seq_len:(index*self.seq_len)+self.seq_len]\n",
    "        y = self.data[1+index*self.seq_len:1+(index*self.seq_len)+self.seq_len]\n",
    "        return x,y\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return self.length\n",
    "\n",
    "class MyDataModule(pl.LightningDataModule):\n",
    "    \n",
    "    def __init__(self, dir_path:str, file_name:str, config):\n",
    "        super().__init__()\n",
    "        # self.batch_size = batch_size\n",
    "        # self.data_path = data_path\n",
    "        self.config = config\n",
    "\n",
    "        self.tokenizer = get_tokenizer('basic_english')\n",
    "        self.vocab = build_vocab_from_iterator(map(self.tokenizer,iter(io.open(dir_path+file_name,encoding=\"utf8\"))))\n",
    "                \n",
    "        # url = data_path\n",
    "        # test_filepath, valid_filepath, train_filepath = extract_archive(download_from_url(url))\n",
    "        seqs = None\n",
    "        with open(dir_path+file_name) as f:\n",
    "            seqs = f.readlines()\n",
    "        seqs = [seq for seq in seqs if len(seq.split())<=self.config['filter-seq-len']]\n",
    "\n",
    "        print(f\"total seqs= {len(seqs)}\")\n",
    "        print(seqs[:4])\n",
    "        train, valid = train_test_split(seqs,test_size=0.30,shuffle=False)\n",
    "        valid, test = train_test_split(valid,test_size=0.30, shuffle=False)\n",
    "\n",
    "        with open(dir_path +\"train.tokens\",\"w\") as f:\n",
    "            for seq in train:\n",
    "                f.write(seq)\n",
    "        \n",
    "        with open(dir_path +\"val.tokens\",\"w\") as f:\n",
    "            for seq in valid:\n",
    "                f.write(seq)\n",
    "            \n",
    "        with open(dir_path +\"test.tokens\",\"w\") as f:\n",
    "            for seq in test:\n",
    "                f.write(seq)\n",
    "\n",
    "        train_data = self.data_process(iter(io.open(dir_path +\"train.tokens\", encoding=\"utf8\")))\n",
    "        val_data = self.data_process(iter(io.open(dir_path +\"val.tokens\", encoding=\"utf8\")))\n",
    "        test_data = self.data_process(iter(io.open(dir_path +\"test.tokens\", encoding=\"utf8\")))\n",
    "\n",
    "    \n",
    "        self.train_dataset = AlarmDataset(train_data, self.config['seq-len'], self.config['batch-size'])\n",
    "        self.valid_dataset = AlarmDataset(val_data,self.config['seq-len'], self.config['batch-size'])\n",
    "        self.test_dataset = AlarmDataset(test_data, self.config['seq-len'], self.config['batch-size'])\n",
    "\n",
    "    \n",
    "    def data_process(self, raw_text_iter):\n",
    "        data = [torch.tensor([self.vocab[token] for token in self.tokenizer(item)],dtype=torch.long) for item in raw_text_iter]\n",
    "        return torch.cat(tuple(filter(lambda t: t.numel() > 0, data)))\n",
    "\n",
    "\n",
    "    def prepare_data(self):\n",
    "        \"\"\"\n",
    "            Use this method to do things that might write to disk or that need to be done only from a single GPU in distributed settings.\n",
    "            e.g., download,tokenize,etc…\n",
    "        \"\"\" \n",
    "        return None\n",
    "\n",
    "\n",
    "    def setup(self, stage: None):\n",
    "        \"\"\"\n",
    "            There are also data operations you might want to perform on every GPU. Use setup to do things like:\n",
    "            count number of classes,build vocabulary,perform train/val/test splits,apply transforms (defined explicitly in your datamodule or assigned in init),etc…\n",
    "        \"\"\"\n",
    "        return None\n",
    "\n",
    "    def train_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(self.train_dataset, batch_size=self.config['batch-size'], shuffle=False,num_workers=8,drop_last=True, pin_memory=True)\n",
    "    \n",
    "    def val_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(self.valid_dataset, batch_size=self.config['batch-size'], shuffle=False,num_workers=8,drop_last=True, pin_memory=True)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.config['batch-size'], shuffle=False,num_workers=8,drop_last=True, pin_memory=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.config = config        \n",
    "        self.lr = self.config[\"lr\"]\n",
    "        self.weight_decay = self.config[\"weight-decay\"]\n",
    "    \n",
    "        self.pos_encoder = PositionalEncoding(self.config['em-size'], self.config['dropout'])\n",
    "        encoder_layers = torch.nn.TransformerEncoderLayer(self.config['em-size'], self.config['nhead'], self.config['nhid'], self.config[\"dropout\"])\n",
    "        self.transformer_encoder = torch.nn.TransformerEncoder(encoder_layers, self.config['nlayers'])\n",
    "        self.encoder = torch.nn.Embedding(self.config[\"vocab-size\"], self.config['em-size'])\n",
    "        self.decoder = torch.nn.Linear(self.config['em-size'], self.config[\"vocab-size\"])\n",
    "        self.src_mask = self.generate_square_subsequent_mask(self.config['seq-len'])\n",
    "        self.init_weights()\n",
    "\n",
    "        class_weights = torch.ones(self.config['vocab-size']) * (1.0/self.config['vocab-size'])\n",
    "        self.class_weights = class_weights.cuda()\n",
    "\n",
    "        self.train_F1 = metrics.classification.F1(num_classes=self.config[\"vocab-size\"])\n",
    "        self.val_F1 = metrics.classification.F1(num_classes=self.config[\"vocab-size\"])\n",
    "        self.test_F1 = metrics.classification.F1(num_classes=self.config[\"vocab-size\"])\n",
    "\n",
    "        self.val_MCR = MyClassificationReport()\n",
    "        self.test_MCR = MyClassificationReport()\n",
    "        \n",
    "\n",
    "\n",
    "        self.log(\"Sequence length\",self.config['seq-len'])\n",
    "        self.log(\"lr\",self.lr)\n",
    "        self.log(\"# of tokens/vocab_size (unique alarms)\",self.config['vocab-size'])\n",
    "        self.log(\"weight_decay\",self.weight_decay)\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src, src_mask):\n",
    "        src_mask = src_mask.to(self.device)\n",
    "        src = self.encoder(src) * math.sqrt(self.config['em-size'])\n",
    "        src = self.pos_encoder(src)\n",
    "      \n",
    "        output = self.transformer_encoder(src, src_mask)\n",
    "        output = self.decoder(output)\n",
    "        \n",
    "        return output\n",
    "\n",
    "   # The ReduceLROnPlateau scheduler requires a monitor\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr,weight_decay=self.weight_decay)\n",
    "        d = {\n",
    "       'optimizer': optimizer,\n",
    "       'lr_scheduler': torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode = \"min\", factor = 0.5, patience=8, verbose=True),\n",
    "       'monitor': 'val_epoch_loss',\n",
    "        'interval': 'epoch'\n",
    "        }\n",
    "        return d    \n",
    "    \n",
    "    def training_step(self,batch,batch_idx):\n",
    "        x,y = batch\n",
    "        x = x.T\n",
    "        y = y.T.reshape(-1)\n",
    "\n",
    "        if x.size(0) != self.config['seq-len']:\n",
    "           self.src_mask =  self.generate_square_subsequent_mask(x.size(0))\n",
    "        \n",
    "        y_hat = self(x,self.src_mask)\n",
    "        y_hat =  y_hat.view(-1, self.config['vocab-size'])\n",
    "        loss = F.cross_entropy(y_hat,y, weight=self.class_weights) # cross entropy itself compute softmax \n",
    "        \n",
    "        self.log('train_loss',loss,logger=True)\n",
    "        self.log('train_F1',self.train_F1(F.softmax(y_hat),y),logger=True, on_step=True,prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self,batch, batch_idx):\n",
    "        x,y = batch\n",
    "        x = x.T\n",
    "        y = y.T.reshape(-1)\n",
    "        \n",
    "        if x.size(0) != self.config['seq-len']:\n",
    "           self.src_mask =  self.generate_square_subsequent_mask(x.size(0))\n",
    "        \n",
    "        y_hat = self(x,self.src_mask)\n",
    "        y_hat =  y_hat.view(-1, self.config['vocab-size'])\n",
    "        loss = F.cross_entropy(y_hat,y,weight=self.class_weights)\n",
    "\n",
    "        self.val_MCR(F.softmax(y_hat) ,y)\n",
    "\n",
    "        self.log('val_loss',loss,logger=True)\n",
    "        self.log('val_F1',self.val_F1(F.softmax(y_hat) ,y),logger=True, prog_bar=True)\n",
    "        return {'val_loss':loss}\n",
    "    \n",
    "    def test_step(self,batch, batch_idx):\n",
    "        x,y = batch\n",
    "        x = x.T\n",
    "        y = y.T.reshape(-1)\n",
    "        if x.size(0) != self.config['seq-len']:\n",
    "           self.src_mask =  self.generate_square_subsequent_mask(x.size(0))\n",
    "\n",
    "        y_hat = self(x,self.src_mask)\n",
    "        y_hat =  y_hat.view(-1,  self.config['vocab-size'])\n",
    "        loss = F.cross_entropy(y_hat,y,weight=self.class_weights)\n",
    "\n",
    "        self.test_F1(F.softmax(y_hat) ,y)\n",
    "        self.test_MCR(F.softmax(y_hat) ,y)\n",
    "        self.log('test_loss',loss,logger=True)\n",
    "        self.log('test_F1', self.test_F1(F.softmax(y_hat) ,y),logger=True)\n",
    "        return {'test_loss':loss}\n",
    "    \n",
    "    def training_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([d['loss']  for d in outputs]).mean()\n",
    "\n",
    "        f1 = self.train_F1.compute()\n",
    "        print(f\">Epoch ={self.current_epoch}, Avg Training loss = {avg_loss}, F1 = {f1}\")\n",
    "        self.log(\"train_epoch_loss\",avg_loss,logger=True,prog_bar=True)\n",
    "        self.log(\"train_epoch_F1\", f1, logger=True,prog_bar=True)\n",
    "  \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([d['val_loss'] for d in outputs]).mean()\n",
    "        # y_hats = torch.stack([d['y_hat'].cpu() for d in outputs])\n",
    "        # ys = torch.stack([d['y'].cpu() for d in outputs])\n",
    "        # ys = ys.view(-1)\n",
    "        # y_hats = y_hats.view(-1,self.config['vocab-size'])\n",
    "\n",
    "        # # print(f\"Shape ys={ys.size()}, y_hats={y_hats.size()}\")\n",
    "        print(\"    **************** Validation Classification Report *****************\")\n",
    "        print(self.val_MCR.compute(),file=open(\"val-output.txt\",'w'))\n",
    "\n",
    "        f1_score = self.val_F1.compute()\n",
    "        print(f\">== Average Valid Loss = {avg_loss}, F1 = {f1_score}\")\n",
    "        self.log(\"val_epoch_loss\",avg_loss,logger=True)\n",
    "        self.log(\"val_epoch_F1\",f1_score,logger=True,prog_bar=True)\n",
    "        \n",
    "    \n",
    "    def test_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([d['test_loss'] for d in outputs]).mean()\n",
    "        f1 = self.test_F1.compute()\n",
    "        \n",
    "\n",
    "\n",
    "        print(f\">Average Test Loss = {avg_loss}, f1= {f1}\")\n",
    "        self.log(\"test_epoch_loss\",avg_loss, logger = True)\n",
    "        self.log(\"test_epoch_F1\",f1, logger=True)\n",
    "        # self.log(\"test_epoch_cm\",cm, logger=True)\n",
    "\n",
    "        print(\"    **************** Test Classification Report *****************\")\n",
    "        print(self.test_MCR.compute(),file=open(\"test-output.txt\",'w'))\n",
    "    "
   ]
  },
  {
   "source": [
    "# Trainning\n",
    "\n",
    "**Note: When monitoring any parameter after the validation epoch end then you should pass check_val_every_n_epoch=1  not to other. This is very important.**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "30825lines [00:02, 14111.43lines/s]\n",
      "total seqs= 27975\n",
      "['A17 A75 A17 A57 A17 A99 A98 A56\\n', 'A245 A246 A50 A243\\n', 'A243 A9 A559 A1025\\n', 'A50 A59 A60 A64 A392 A726 A9 A725 A726 A725 A243 A725\\n']\n"
     ]
    }
   ],
   "source": [
    "dir_name = \"../.data/\"\n",
    "fname = 'seqs.tokens'\n",
    "\n",
    "# setup data\n",
    "config_data = {\n",
    "'batch-size' :16, # Batch Size \n",
    "'seq-len' : 700, # Sequence length\n",
    "'filter-seq-len' :350 # remove sequence whose size is greater than this len\n",
    "}\n",
    "\n",
    "dm = MyDataModule(dir_path=dir_name,file_name=fname,config=config_data)\n",
    "\n",
    "\n",
    "config_model = {\n",
    "    'lr' : 0.0001,\n",
    "    'dropout' : 0.1,\n",
    "    'weight-decay': 0.0003,\n",
    "    'em-size' :256, # embedding dimension \n",
    "    'nhid' : 266, # the dimension of the feedforward network model in nn.TransformerEncoder\n",
    "    'nlayers' :3, # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "    'nhead' : 8, # the number of heads in the multiheadattention models\n",
    "    'seq-len': config_data['seq-len'], # dont use wandb config \n",
    "    'vocab-size':len(dm.vocab.stoi) # the size of vocabulary /also called tokens\n",
    "}\n",
    "\n",
    "# setup model - note how we refer to sweep parameters with wandb.config\n",
    "model = TransformerModel(config=config_model)\n"
   ]
  },
  {
   "source": [
    "## Loggers"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "CometLogger will be initialized in online mode\n"
     ]
    }
   ],
   "source": [
    "wandb_logger = WandbLogger(project=\"Alarm-Transformers-Net\")\n",
    "comet_logger = CometLogger(\n",
    "    api_key=\"YZWScOiWdE8FwQSUj725dRmor\",\n",
    "    project_name=\"Alarm-Transformers-Net\" # Optional\n",
    ")\n",
    "test_tube_logger = TestTubeLogger('tb_logs', name='Alarm-Transformers-Net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Using native 16bit precision.\n",
      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwaris\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                Tracking run with wandb version 0.10.14<br/>\n                Syncing run <strong style=\"color:#cdcd00\">playful-sound-2309</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://wandb.ai/waris/Alarm-Transformers-Net\" target=\"_blank\">https://wandb.ai/waris/Alarm-Transformers-Net</a><br/>\n                Run page: <a href=\"https://wandb.ai/waris/Alarm-Transformers-Net/runs/33wdbupf\" target=\"_blank\">https://wandb.ai/waris/Alarm-Transformers-Net/runs/33wdbupf</a><br/>\n                Run data is saved locally in <code>/home/waris/Github/predict-future-alarms/project/wandb/run-20210122_105813-33wdbupf</code><br/><br/>\n            "
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "  | Name                | Type                   | Params\n",
      "---------------------------------------------------------------\n",
      "0 | pos_encoder         | PositionalEncoding     | 0     \n",
      "1 | transformer_encoder | TransformerEncoder     | 1.2 M \n",
      "2 | encoder             | Embedding              | 245 K \n",
      "3 | decoder             | Linear                 | 246 K \n",
      "4 | train_F1            | F1                     | 0     \n",
      "5 | val_F1              | F1                     | 0     \n",
      "6 | test_F1             | F1                     | 0     \n",
      "7 | val_MCR             | MyClassificationReport | 0     \n",
      "8 | test_MCR            | MyClassificationReport | 0     \n",
      "---------------------------------------------------------------\n",
      "1.7 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.7 M     Total params\n",
      ">== Average Valid Loss = 7.241314888000488, F1 = 0.00022321428696159273\n",
      "    **************** Validation Classification Report *****************\n",
      ">Epoch =0, Avg Training loss = 1.336412787437439, F1 = 0.7925863265991211\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "MisconfigurationException",
     "evalue": "ReduceLROnPlateau conditioned on metric val_epoch_loss which is not available. Available metrics are: dict_keys(['train_F1', 'train_loss', 'train_epoch_loss', 'train_epoch_F1']). Condition can be set using `monitor` key in lr scheduler dict",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMisconfigurationException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-0fdaa7dbb880>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# setup Trainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_nodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_val_every_n_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwandb_logger\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mgradient_clip_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0menable_pl_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stop_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprogress_bar_refresh_rate\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# traning and validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'on_fit_start'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    471\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/accelerators/gpu_accelerator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;31m# train or test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_or_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mtrain_or_test\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m                 \u001b[0;31m# update LR schedulers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_connector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_learning_rates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0;31m# early stopping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/optimizer_connector.py\u001b[0m in \u001b[0;36mupdate_learning_rates\u001b[0;34m(self, interval, monitor_metrics)\u001b[0m\n\u001b[1;32m     54\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'strict'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                             \u001b[0mavail_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger_connector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m                             raise MisconfigurationException(\n\u001b[0m\u001b[1;32m     57\u001b[0m                                 \u001b[0;34mf'ReduceLROnPlateau conditioned on metric {monitor_key}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                                 \u001b[0;34mf' which is not available. Available metrics are: {avail_metrics}.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMisconfigurationException\u001b[0m: ReduceLROnPlateau conditioned on metric val_epoch_loss which is not available. Available metrics are: dict_keys(['train_F1', 'train_loss', 'train_epoch_loss', 'train_epoch_F1']). Condition can be set using `monitor` key in lr scheduler dict"
     ]
    }
   ],
   "source": [
    "early_stop_callback = EarlyStopping(\n",
    "   monitor='val_epoch_loss',\n",
    "   min_delta=0.00,\n",
    "   patience=20,\n",
    "   verbose=True,\n",
    "   mode='min'\n",
    ")\n",
    "\n",
    "# setup Trainer\n",
    "trainer = Trainer(precision=16,gpus=-1, num_nodes=1,  max_epochs=1, check_val_every_n_epoch=10,deterministic=True, logger=[wandb_logger] ,gradient_clip_val=0.5,enable_pl_optimizer=True,callbacks=[early_stop_callback],progress_bar_refresh_rate =0)\n",
    "trainer.fit(model,dm) # traning and validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.test(datamodule=dm) # testing"
   ]
  },
  {
   "source": [
    "# accelerator='dp'\n",
    "# progress_bar_refresh_rate=0 # set to zero to disable it"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.ones(5) * 1/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('dl': conda)",
   "metadata": {
    "interpreter": {
     "hash": "8076afad8c2f739e22f417bad77704dbad7b0389c4d6903b1ae4a1b7479f7ed3"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}