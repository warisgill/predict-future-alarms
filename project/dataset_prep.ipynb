{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('dl': conda)",
   "metadata": {
    "interpreter": {
     "hash": "8076afad8c2f739e22f417bad77704dbad7b0389c4d6903b1ae4a1b7479f7ed3"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "import time\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterAlarmData(df, months=None, sources_filter=[], monmentarly_filter=None, staling_filter=None ,ingore_communication_alarms=False, min_alarms_per_source=10):\n",
    "\n",
    "    print(f\">>Preprocessing... \\n   Months to include={months}\\n  Ignore Sources={sources_filter}\\n  Ingnore Momentarlily Alarms Filter={monmentarly_filter}seconds \\n   Ignoreing Staling Alarms Filter={staling_filter} seconds, \\n Ignore Communication Alarms = {ingore_communication_alarms} \\n Remove sources whose count is less than {min_alarms_per_source}\")\n",
    "    \n",
    "    \n",
    "    if months is None:\n",
    "        months = df[\"Year-Month\"].unique()\n",
    "\n",
    "    if monmentarly_filter is not None: \n",
    "        df = df[(df[\"TimeDelta\"] > monmentarly_filter)]\n",
    "\n",
    "    if staling_filter is not None:\n",
    "        df =  df[(df[\"TimeDelta\"] < staling_filter)]\n",
    "\n",
    "    if ingore_communication_alarms==True:\n",
    "        df = df[~df[\"Condition\"].isin([\"IOP\", \"IOP-\"])]\n",
    "    \n",
    "    df =  df[(df[\"Year-Month\"].isin(months))]\n",
    "    df = df[(~df[\"SourceName\"].isin(sources_filter))]\n",
    "\n",
    "    source2count = dict(df[\"SourceName\"].value_counts())\n",
    "    select_sources = [k for k, v in source2count.items() if v >= min_alarms_per_source]\n",
    "    df = df[df[\"SourceName\"].isin(select_sources)]\n",
    "\n",
    "    return df\n",
    "\n",
    "def _concatenateSourceNameAndCondition(sname, condition):\n",
    "    return sname+\"-\"+condition\n",
    "\n",
    "\n",
    "def updatSourceNamewithCondition(df):\n",
    "    df[\"SourceName\"] = df[[\"SourceName\", \"Condition\"]].apply(\n",
    "        lambda arg: _concatenateSourceNameAndCondition(*arg), axis=1)\n",
    "    return df\n",
    "\n",
    "def convertSourceNamesToAlias(df):\n",
    "    alias2name = {f\"A{k}\": v for k, v in enumerate(df[\"SourceName\"].unique())}\n",
    "    name2alias = {v: k for k, v in alias2name.items()}\n",
    "    df[\"SourceName\"] = df[\"SourceName\"].apply(lambda sname: name2alias[sname])\n",
    "    return name2alias, alias2name\n",
    "\n",
    "def __removeChatteringAlarmsHelper(alarms, chattering_timedelta_threshold=60.0, chattering_count_threshold=3):\n",
    "    \"\"\"Find the chatterings in an alarms list from the same source.  \n",
    "    \"\"\"\n",
    "\n",
    "    alarms_without_chattering = []\n",
    "    alarms = [alarm for alarm in sorted(alarms, key=lambda arg: arg[\"StartTime\"], reverse=False)]\n",
    "    i = 0\n",
    "    j = 0\n",
    "\n",
    "    while i < (len(alarms)):\n",
    "        alarms_without_chattering.append(alarms[i])\n",
    "        prev_start = alarms[i][\"StartTime\"]\n",
    "        prev_end = alarms[i][\"EndTime\"]\n",
    "        count_alarms = 0\n",
    "        j = i + 1\n",
    "        while j < len(alarms):\n",
    "            next_start = alarms[j][\"StartTime\"]\n",
    "            next_end = alarms[j][\"EndTime\"]\n",
    "\n",
    "            # this assert is very important: the prev alarm has to turn off before the start of\n",
    "            # the next one\n",
    "            assert(prev_start <= next_start)\n",
    "            assert(prev_end <= next_start)\n",
    "            assert(prev_end <= next_end)\n",
    "\n",
    "            delta = timedelta.total_seconds(next_start - prev_start)\n",
    "            assert (delta >= 0)\n",
    "            \n",
    "            if delta > chattering_timedelta_threshold:\n",
    "                break\n",
    "            count_alarms += 1\n",
    "            \n",
    "            j += 1\n",
    "        \n",
    "        if count_alarms >= chattering_count_threshold:\n",
    "            i = j\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "    return alarms_without_chattering\n",
    "\n",
    "def removeChatteringAlarms(df):\n",
    "    alarms_without_chatterings = []\n",
    "    for sname in df[\"SourceName\"].unique():\n",
    "        df_source = df.loc[df['SourceName'].isin([sname])]\n",
    "\n",
    "        for condition in df_source[\"Condition\"].unique():\n",
    "            df_condition = df_source.loc[df_source['Condition'].isin([condition])]\n",
    "            alarms = __removeChatteringAlarmsHelper(df_condition.to_dict(orient=\"records\"))\n",
    "            alarms_without_chatterings = alarms_without_chatterings + alarms\n",
    "\n",
    "    return pd.DataFrame(alarms_without_chatterings)\n",
    "\n",
    "def loadAlarmsData(file_path):\n",
    "    df = pd.read_csv(file_path, low_memory=False, usecols=[\"SourceName\", \"Condition\", \"StartTime\",\"EndTime\",\"TimeDelta\",\"Year-Month\"],parse_dates=[\"StartTime\", \"EndTime\"])\n",
    "    return df\n",
    "\n",
    "def getDFWithCommonSourcesInAllMonths(df):\n",
    "    each_month_source_names = [[sname for sname in df[df[\"Year-Month\"]==month][\"SourceName\"].unique()] for month in df[\"Year-Month\"].unique()]\n",
    "    common_sourcenames_in_all_months = set.intersection(*[set(l) for l in each_month_source_names])\n",
    "    df = df[df[\"SourceName\"].isin(common_sourcenames_in_all_months)]\n",
    "    return df\n",
    "\n",
    "def getSequenceOfWholeData(df,seq_duration_gap,filter_short_seq):\n",
    "    print(f\">> Duration to next seq: {seq_duration_gap}, ignore seq len: {filter_short_seq}\")\n",
    "\n",
    "    list_of_sequences = []    \n",
    "    alarms= df.to_dict(orient=\"records\")\n",
    "    alarms = [alarm for alarm in sorted(alarms, key=lambda arg: arg[\"StartTime\"], reverse=False)] # sorting\n",
    "    i =0\n",
    "    j= 0\n",
    "\n",
    "    max_seq_len = -1\n",
    "    while i <len(alarms):\n",
    "        prev_start = alarms[i][\"StartTime\"]\n",
    "        seq = []\n",
    "        seq.append(alarms[i])\n",
    "        j = i+1\n",
    "        while j < len(alarms):    \n",
    "            next_start = alarms[j][\"StartTime\"]\n",
    "            delta = timedelta.total_seconds(next_start - prev_start)\n",
    "            # print(delta)\n",
    "            assert delta >= 0\n",
    "            if delta >= seq_duration_gap:\n",
    "                break\n",
    "\n",
    "            seq.append(alarms[j])\n",
    "            j += 1\n",
    "        i = j\n",
    "\n",
    "        if len(seq) > max_seq_len:\n",
    "            max_seq_len = len(seq)\n",
    "        \n",
    "        if len(seq)>=filter_short_seq:\n",
    "            seq = [alarm for alarm in sorted(seq, key=lambda arg: arg[\"StartTime\"], reverse=False)]\n",
    "            seq = [alarm[\"SourceName\"] for alarm in seq]\n",
    "            list_of_sequences.append(seq)\n",
    "    \n",
    "    \n",
    "    return list_of_sequences, max_seq_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"  Lodading the Data and Preprocessing \"\"\"\n",
    "start = time.time()\n",
    "\n",
    "df_main_alarms =loadAlarmsData(file_path=\"/home/waris/Github/predict-future-alarms/.data/final-all-months-alarms.csv\")\n",
    "df_main_alarms = updatSourceNamewithCondition(df_main_alarms)\n",
    "print(\"Total Time to load the data \", time.time()-start)\n",
    "\n",
    "df_main_alarms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\" Chaning name 2 alias for alarm data but skipping it \"\"\"\n",
    "source2Alias, alias2source = convertSourceNamesToAlias(df_main_alarms)\n",
    "df_main_alarms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "    Filter the Alarm Data\n",
    "    1. Ignore the communication Alarms\n",
    "    2. Ignore the momentary alarms => 20 seconds\n",
    "    3. Remove Staling Alarms => 12 hours    \n",
    "    4. Remove sources which are triggered less 20 in whole dataset\n",
    "    5. Include all the months\n",
    "    6. DO SKIP ANY SOURCENAME IF IGNORING COMMUNICATION ALARMS\n",
    "\"\"\"\n",
    "ignore_comm_alarms = True\n",
    "momentary_alarms_f = None # seconds\n",
    "staling_alarm_f = None # hours\n",
    "min_alarms_per_source_f = 20 # any source which is not triggered atleast 20 times in whole dataset will be removed\n",
    "months_f = df_main_alarms[\"Year-Month\"].unique()\n",
    "snames_f = [] # ONLY USE IF NOT IGNORING COMM ALRMS\n",
    "\n",
    "df_alarms_new = filterAlarmData(df_main_alarms, months=months_f, sources_filter=snames_f,\n",
    "                                     monmentarly_filter=momentary_alarms_f, staling_filter=staling_alarm_f, ingore_communication_alarms=ignore_comm_alarms, min_alarms_per_source=min_alarms_per_source_f)\n",
    "\n",
    "\n",
    "df_alarms_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rnn = removeChatteringAlarms(df_alarms_new)\n",
    "df_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_from_1_seq_to_next = 60*15 # duration in seconds\n",
    "filter_short_seq = 4 # remove the sequence whose size is less than 4\n",
    "li_of_seqs,max_seq_len = getSequenceOfWholeData(df_rnn,duration_from_1_seq_to_next,filter_short_seq)\n",
    "print(len(li_of_seqs))\n",
    "print(li_of_seqs[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/waris/Github/predict-future-alarms/.data/seqs.tokens\",\"w\") as f:\n",
    "    for seq in li_of_seqs:\n",
    "        f.write(f\"{' '.join(seq)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}