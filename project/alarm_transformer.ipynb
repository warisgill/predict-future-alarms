{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('dl': conda)",
   "metadata": {
    "interpreter": {
     "hash": "8076afad8c2f739e22f417bad77704dbad7b0389c4d6903b1ae4a1b7479f7ed3"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import io\n",
    "import torchtext\n",
    "from torchtext.utils import download_from_url, extract_archive\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.trainer.trainer import Trainer\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "\n",
    "from pytorch_lightning import seed_everything\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "30551lines [00:00, 54856.64lines/s]\n",
      "['A17 A17 A17 A75 A17 A57 A17 A17 A17 A98 A99 A56\\n', 'A245 A246 A50 A243\\n', 'A50 A59 A60 A64 A392 A726 A726 A726 A9 A725 A726 A726 A725 A725 A725 A243 A725\\n', 'A746 A17 A266 A563 A204 A613 A367 A1094\\n']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class AlarmDataset(Dataset):\n",
    "    def __init__(self,data,seq_len,batch_size):\n",
    "        self.length = len(data)//seq_len # how much data i have         \n",
    "        self.data = data\n",
    "        self.seq_len = seq_len\n",
    "        self.batch_size = batch_size\n",
    "       \n",
    "    def __getitem__(self, index: int):\n",
    "        x = self.data[index*self.seq_len:(index*self.seq_len)+seq_len]\n",
    "        y = self.data[1+index*self.seq_len:1+(index*self.seq_len)+seq_len]\n",
    "        return x,y\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return self.length\n",
    "\n",
    "class MyDataModule(pl.LightningDataModule):\n",
    "    \n",
    "    def __init__(self, data_path:str, batch_size:int, seq_len:int):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.tokenizer = get_tokenizer('basic_english')\n",
    "        self.vocab = build_vocab_from_iterator(map(self.tokenizer,iter(io.open(data_path,encoding=\"utf8\"))))\n",
    "                \n",
    "        # url = data_path\n",
    "        # test_filepath, valid_filepath, train_filepath = extract_archive(download_from_url(url))\n",
    "        seqs = None\n",
    "        with open(data_path) as f:\n",
    "            seqs = f.readlines()\n",
    "        print(seqs[:4])\n",
    "        train, valid = train_test_split(seqs,test_size=0.30,shuffle=False)\n",
    "        valid, test = train_test_split(valid,test_size=0.30, shuffle=False)\n",
    "\n",
    "        \n",
    "\n",
    "        with open(\"../.data/train.tokens\",\"w\") as f:\n",
    "            for seq in train:\n",
    "                f.write(seq)\n",
    "        \n",
    "        with open(\"../.data/val.tokens\",\"w\") as f:\n",
    "            for seq in valid:\n",
    "                f.write(seq)\n",
    "            \n",
    "        with open(\"../.data/test.tokens\",\"w\") as f:\n",
    "            for seq in test:\n",
    "                f.write(seq)\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        train_data = self.data_process(iter(io.open(\"../.data/train.tokens\", encoding=\"utf8\")))\n",
    "        val_data = self.data_process(iter(io.open(\"../.data/val.tokens\", encoding=\"utf8\")))\n",
    "        test_data = self.data_process(iter(io.open(\"../.data/test.tokens\", encoding=\"utf8\")))\n",
    "\n",
    "    \n",
    "        self.train_dataset = AlarmDataset(train_data, seq_len,self.batch_size)\n",
    "        self.valid_dataset = AlarmDataset(val_data,seq_len,self.batch_size)\n",
    "        self.test_dataset = AlarmDataset(test_data, seq_len,self.batch_size)\n",
    "    \n",
    "    def data_process(self, raw_text_iter):\n",
    "        data = [torch.tensor([self.vocab[token] for token in self.tokenizer(item)],dtype=torch.long) for item in raw_text_iter]\n",
    "        return torch.cat(tuple(filter(lambda t: t.numel() > 0, data)))\n",
    "\n",
    "\n",
    "    def setup(self, stage: None):\n",
    "        return None\n",
    "\n",
    "    def train_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=False,num_workers=1,drop_last=True, pin_memory=True)\n",
    "    \n",
    "    def val_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(self.valid_dataset, batch_size=self.batch_size, shuffle=False,num_workers=1,drop_last=True, pin_memory=True)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False,num_workers=1,drop_last=True, pin_memory=True)\n",
    "\n",
    "file_path = '../.data/seqs.tokens'\n",
    "\n",
    "bsize = 20\n",
    "seq_len = 35\n",
    "dm = MyDataModule(file_path,bsize,seq_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.5, seq_len=None):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.ntoken = ntoken\n",
    "        self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
    "        encoder_layers = torch.nn.TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n",
    "        self.transformer_encoder = torch.nn.TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.encoder = torch.nn.Embedding(ntoken, ninp)\n",
    "        self.ninp = ninp\n",
    "        self.decoder = torch.nn.Linear(ninp, ntoken)\n",
    "        self.src_mask = self.generate_square_subsequent_mask(seq_len)\n",
    "        self.seq_len = seq_len \n",
    "        self.init_weights()\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src, src_mask):\n",
    "        src_mask = src_mask.to(self.device)\n",
    "        src = self.encoder(src) * math.sqrt(self.ninp)\n",
    "        src = self.pos_encoder(src)\n",
    "        src_mask = src_mask.to(self.device)\n",
    "      \n",
    "        output = self.transformer_encoder(src, src_mask)\n",
    "        output = self.decoder(output)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.001, weight_decay=0.0000001)\n",
    "        return optimizer\n",
    "    \n",
    "    def training_step(self,batch,batch_idx):\n",
    "        x,y = batch\n",
    "        x = x.T\n",
    "        y = y.T.reshape(-1)\n",
    "\n",
    "        # print(\"Training Shape: \", x.size(),y.size())\n",
    "        \n",
    "        if x.size(0) != self.seq_len:\n",
    "           self.src_mask =  self.generate_square_subsequent_mask(x.size(0))\n",
    "        \n",
    "        y_hat = self(x,self.src_mask)\n",
    "\n",
    "        loss = F.cross_entropy(y_hat.view(-1, self.ntoken),y)\n",
    "        self.log('train_loss', loss,on_step=True, prog_bar=True, logger=True)\n",
    "        self.log(\"train_ppl\",math.exp(loss.item()),on_step=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self,batch, batch_idx):\n",
    "        x,y = batch\n",
    "        x = x.T\n",
    "        y = y.T.reshape(-1)\n",
    "\n",
    "        # print(\"Validation Shape: \", x.size(),y.size())\n",
    "\n",
    "        if x.size(0) != self.seq_len:\n",
    "           self.src_mask =  self.generate_square_subsequent_mask(x.size(0))\n",
    "        \n",
    "        y_hat = self(x,self.src_mask)\n",
    "        # print(\"> y-hat\",y_hat.size())\n",
    "        loss = F.cross_entropy(y_hat.view(-1, self.ntoken),y)\n",
    "        self.log('val_loss', loss, on_step=True, prog_bar=True, logger=True)\n",
    "        self.log(\"val_ppl\",math.exp(loss.item()),on_step=True, prog_bar=True, logger=True)\n",
    "        return {'val_loss':loss}\n",
    "    \n",
    "    def test_step(self,batch, batch_idx):\n",
    "        x,y = batch\n",
    "        x = x.T\n",
    "        y = y.T.reshape(-1)\n",
    "\n",
    "        # print(\"Validation Shape: \", x.size(),y.size())\n",
    "\n",
    "        if x.size(0) != self.seq_len:\n",
    "           self.src_mask =  self.generate_square_subsequent_mask(x.size(0))\n",
    "        \n",
    "        y_hat = self(x,self.src_mask)\n",
    "        # print(\"> y-hat\",y_hat.size())\n",
    "        loss = F.cross_entropy(y_hat.view(-1, self.ntoken),y)\n",
    "        self.log('test_loss', loss, on_step=True, prog_bar=True, logger=True)\n",
    "        self.log(\"test_ppl\",math.exp(loss.item()),on_step=True, prog_bar=True, logger=True)\n",
    "        return {'test_loss':loss}\n",
    "    \n",
    "    def training_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([d['loss']  for d in outputs]).mean()\n",
    "        print(f\"> Avg Training loss = {avg_loss}\")\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        # print(outputs)\n",
    "        avg_loss = torch.stack([d['val_loss'] for d in outputs]).mean()\n",
    "        print(f\"> Average Valid Loss = {avg_loss}\")\n",
    "    \n",
    "    def test_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([d['test_loss'] for d in outputs]).mean()\n",
    "        print(f\"> Average Test Loss = {avg_loss}\")\n",
    "    \n",
    "    \n",
    "class PositionalEncoding(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "30551lines [00:00, 55218.51lines/s]\n",
      "['A17 A17 A17 A75 A17 A57 A17 A17 A17 A98 A99 A56\\n', 'A245 A246 A50 A243\\n', 'A50 A59 A60 A64 A392 A726 A726 A726 A9 A725 A726 A726 A725 A725 A725 A243 A725\\n', 'A746 A17 A266 A563 A204 A613 A367 A1094\\n']\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Using native 16bit precision.\n",
      "\n",
      "  | Name                | Type               | Params\n",
      "-----------------------------------------------------------\n",
      "0 | pos_encoder         | PositionalEncoding | 0     \n",
      "1 | transformer_encoder | TransformerEncoder | 484 K \n",
      "2 | encoder             | Embedding          | 138 K \n",
      "3 | decoder             | Linear             | 139 K \n",
      "-----------------------------------------------------------\n",
      "762 K     Trainable params\n",
      "0         Non-trainable params\n",
      "762 K     Total params\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validation sanity check: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "37cc12053bd84938958c385fd57e9463"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "> Average Valid Loss = 6.519143104553223\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "639e4077973c474fb4755ab1af3f3b53"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e652bf5fec634791933d78b6c4781774"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "> Average Valid Loss = 2.987840414047241\n> Avg Training loss = 1.9766099452972412\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1fe806f9cc554f60bd28a19a23ff2090"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "> Average Valid Loss = 2.885150194168091\n> Avg Training loss = 1.7431257963180542\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "503260bedfcf4b8d81a4a32353ff2236"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "> Average Valid Loss = 2.885382890701294\n> Avg Training loss = 1.6885005235671997\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "28fbaa5c9818474b888e33599ea14896"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "> Average Valid Loss = 2.8332700729370117\n> Avg Training loss = 1.646619200706482\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9f6fcc7c3cbb4fe48d24ceccaaf8e243"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "> Average Valid Loss = 2.8899593353271484\n> Avg Training loss = 1.6184449195861816\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "51e2e9e1c08d4129aa4c5afe51b5cec1"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "> Average Valid Loss = 2.878481864929199\n> Avg Training loss = 1.5973347425460815\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5c9f8daeb854439d8cffe49ce8c5c000"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "> Average Valid Loss = 2.823499917984009\n> Avg Training loss = 1.5788036584854126\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "567bd0a3d71842bbbfa8760cfda78f57"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "> Average Valid Loss = 2.7876315116882324\n> Avg Training loss = 1.5707781314849854\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "75c6cfbdbfc84561848efacf0c31298f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "> Average Valid Loss = 2.760228157043457\n> Avg Training loss = 1.562995433807373\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ed54b953f2a948f686b6bcab39234962"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "> Average Valid Loss = 2.7077765464782715\n> Avg Training loss = 1.553634762763977\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "58843e58b7e9467db6d5bba30b1a2761"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "> Average Valid Loss = 2.67106294631958\n> Avg Training loss = 1.547193169593811\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f6c665ce903b48f8b67ec1a452ddc381"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "> Average Valid Loss = 2.7941792011260986\n> Avg Training loss = 1.5428318977355957\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "77eea509f6534139bc41d9d519608c8a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "> Average Valid Loss = 2.743276357650757\n> Avg Training loss = 1.536960482597351\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "53e499fe84484dbc863a698dfc3c720c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "> Average Valid Loss = 2.6819145679473877\n> Avg Training loss = 1.5272958278656006\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "247600928ffa44ada74d2f927d734e9d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "> Average Valid Loss = 2.7427215576171875\n> Avg Training loss = 1.5231577157974243\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5c0b37468a0c4bc480d6bd0d8d50bb56"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "> Average Valid Loss = 2.696821928024292\n> Avg Training loss = 1.5184237957000732\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "269ab220db6547f396d4621802ca6b50"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "> Average Valid Loss = 2.6438236236572266\n> Avg Training loss = 1.51895010471344\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4bc82ba16db44e9781b05e8a78635cd5"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "> Average Valid Loss = 2.720628261566162\n> Avg Training loss = 1.5160142183303833\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "98d7c079e37f48bd9129061b7893ffb5"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "> Average Valid Loss = 2.7121009826660156\n> Avg Training loss = 1.5146926641464233\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9e1bf1c42bbe436795b663a1445017fa"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "> Average Valid Loss = 2.744326591491699\n> Avg Training loss = 1.5099523067474365\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "234da4553363481bb59edbb34933e1ec"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "> Average Valid Loss = 2.7432701587677\n> Avg Training loss = 1.5083099603652954\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e6faa7349027409fbdc9963b51fb91f7"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "> Average Valid Loss = 2.7878241539001465\n> Avg Training loss = 1.5060663223266602\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6acc0bcdfc794460a62887f0a35677a9"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "> Average Valid Loss = 2.6685454845428467\n> Avg Training loss = 1.510250449180603\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fe38c00493ca442ba7ca988fe0991d0b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "> Average Valid Loss = 2.730907440185547\n> Avg Training loss = 1.5051714181900024\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0194e7dd4c82494793e34d2ccb71b052"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "> Average Valid Loss = 2.725038766860962\n> Avg Training loss = 1.5014500617980957\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5577145cbf274bcb97347c512b816e48"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "> Average Valid Loss = 2.777764320373535\n> Avg Training loss = 1.4997276067733765\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6d6146ad9e7749a78e5113f45cdfc441"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "> Average Valid Loss = 2.734978437423706\n> Avg Training loss = 1.49988853931427\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8775906d921c4fe3a6b975824b3ba770"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "> Average Valid Loss = 2.851977586746216\n> Avg Training loss = 1.4954900741577148\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "967dfd00bbdf45daa7088221d730430b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "> Average Valid Loss = 2.7137157917022705\n> Avg Training loss = 1.4943643808364868\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "902c6dbcd64942f88d7aa40e4b1d80b5"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "> Average Valid Loss = 2.732642889022827\n> Avg Training loss = 1.493984580039978\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "77e88c5529e64466971731fc09a6b7ac"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "> Average Valid Loss = 2.666787624359131\n> Avg Training loss = 1.4919896125793457\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5172e90dd20148d1bbb1162d1aea40ad"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "> Average Valid Loss = 2.6962642669677734\n> Avg Training loss = 1.4927773475646973\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1b12c9adc3984c9f8c3163dfe109531f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "> Average Valid Loss = 2.6638636589050293\n> Avg Training loss = 1.4900317192077637\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "86c34e1050d14bd195fe037a969edfc7"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "> Average Valid Loss = 2.6541759967803955\n> Avg Training loss = 1.4900648593902588\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "68a3a9d5d3ec47918b0366eccb13f4e1"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "> Average Valid Loss = 2.6451241970062256\n> Avg Training loss = 1.4868074655532837\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3cbdf38d36f14923addf66c61219a3db"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "> Average Valid Loss = 2.663384199142456\n> Avg Training loss = 1.4874776601791382\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aabc2deae8ca4faf86a33cb569ad2fe4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "> Average Valid Loss = 2.5947036743164062\n> Avg Training loss = 1.4858081340789795\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "de1353a39a824d62999dcf7fbe0fc49a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "> Average Valid Loss = 2.619311571121216\n> Avg Training loss = 1.486391305923462\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "136f46d12dc94fac919339dadd6b6226"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "> Average Valid Loss = 2.619338274002075\n> Avg Training loss = 1.4847642183303833\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8a2d1698ce8d4445bae6d3ed5c8963dc"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "> Average Valid Loss = 2.6048290729522705\n> Avg Training loss = 1.4864068031311035\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "file_path = '../.data/seqs.tokens'\n",
    "tb_logger = pl_loggers.TensorBoardLogger('logs/')\n",
    "\n",
    "bsize = 32\n",
    "seq_len = 35\n",
    "dm = MyDataModule(file_path,bsize,seq_len)\n",
    "\n",
    "ntokens = len(dm.vocab.stoi) # the size of vocabulary\n",
    "emsize = 200 # embedding dimension\n",
    "nhid = 200 # the dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = 2 # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 2 # the number of heads in the multiheadattention models\n",
    "dropout = 0.2 # the dropout value\n",
    "\n",
    "model = TransformerModel(ntokens, emsize, nhead, nhid, nlayers, dropout,seq_len=seq_len)\n",
    "trainer = Trainer(precision=16,gpus=1,max_epochs=400,check_val_every_n_epoch=4,deterministic=True, gradient_clip_val=0.5,logger=tb_logger)\n",
    "trainer.fit(model,dm) # traning and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Testing: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4549fd77a2b344b3b26293b7f68c7bcb"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "> Average Test Loss = 2.731191635131836\n--------------------------------------------------------------------------------\nDATALOADER:0 TEST RESULTS\n{'test_loss': tensor(2.7468, device='cuda:0'),\n 'test_loss_epoch': tensor(2.7312, device='cuda:0'),\n 'test_ppl': 15.592896266917588,\n 'test_ppl_epoch': tensor(19.3933),\n 'val_loss': tensor(2.1163, device='cuda:0'),\n 'val_loss_epoch': tensor(2.6048, device='cuda:0'),\n 'val_ppl': 8.30071050411446,\n 'val_ppl_epoch': tensor(21.3543)}\n--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'val_loss_epoch': 2.6048288345336914,\n",
       "  'val_ppl_epoch': 21.354297637939453,\n",
       "  'val_loss': 2.1163411140441895,\n",
       "  'val_ppl': 8.30071050411446,\n",
       "  'test_loss_epoch': 2.731191635131836,\n",
       "  'test_ppl_epoch': 19.39333724975586,\n",
       "  'test_loss': 2.7468154430389404,\n",
       "  'test_ppl': 15.592896266917588}]"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "trainer.test(datamodule=dm) # testing\n",
    "# %%"
   ]
  }
 ]
}